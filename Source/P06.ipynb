{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) import tensoflow and other related packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.api.types import CategoricalDtype \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix\n",
    "import keras_tuner as kt\n",
    "\n",
    "#%load_ext tensorboard => I am running tensorboard from Terminal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) import additional packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [9, 6]\n",
    "sns.set_style(\"darkgrid\")\n",
    "base_log_dir = \"./logs/\"\n",
    "\n",
    "if not os.path.exists(base_log_dir):\n",
    "    os.makedirs(base_log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) simple utils to handel some implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateMetricsAndPlot(true_label, predicted_label,color=\"Blues\",text=\"\"):\n",
    "    CM = confusion_matrix(true_label, predicted_label)\n",
    "    acc = round(accuracy_score(true_label,predicted_label)*100,2)\n",
    "    precision = round(precision_score(true_label,predicted_label, average='macro'),2)\n",
    "    if text == \"\":\n",
    "        sns.heatmap(CM ,annot=True, cmap=color, fmt='g').set_title(\"Confusion Matrix for Test Data | Accuracy={0}% | Precision={1}\".format(acc,precision))\n",
    "    else :\n",
    "        sns.heatmap(CM ,annot=True, cmap=color, fmt='g').set_title(\"Confusion Matrix for Test Data | Accuracy={0}% | Precision={1} | {2}\".format(acc,precision,text))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of Train: 60.68%\n",
      "percentage of Validation: 10.71%\n",
      "percentage of Test: 28.61%\n"
     ]
    }
   ],
   "source": [
    "with open('X_test.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "with open('X_valid.npy', 'rb') as f:\n",
    "    X_valid = np.load(f)\n",
    "with open('X_train.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "    \n",
    "with open('Y_test.npy', 'rb') as f:\n",
    "    Y_test = np.load(f)\n",
    "with open('Y_valid.npy', 'rb') as f:\n",
    "    Y_valid = np.load(f)\n",
    "with open('Y_train.npy', 'rb') as f:\n",
    "    Y_train = np.load(f)\n",
    "      \n",
    "Total_count = X_train.shape[0]+X_valid.shape[0]+X_test.shape[0]\n",
    "Y_test,Y_valid,Y_train = Y_test-1,Y_valid-1,Y_train-1\n",
    "\n",
    "print(\"percentage of Train: {0}%\".format(round(X_train.shape[0]/Total_count*100,2)))\n",
    "print(\"percentage of Validation: {0}%\".format(round(X_valid.shape[0]/Total_count*100,2)))\n",
    "print(\"percentage of Test: {0}%\".format(round(X_test.shape[0]/Total_count*100,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom MLP Builder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialANN :\n",
    "    def __init__(self,_shape_input:tuple,label_count,_neurons : list,id=None):\n",
    "        self.model = keras.models.Sequential()\n",
    "        keras.backend.clear_session()\n",
    "        self.model.add(keras.layers.Input(shape=_shape_input))\n",
    "        self.model.add(keras.layers.Flatten())\n",
    "        \n",
    "        for n in range(len(_neurons)) :\n",
    "            self.model.add(keras.layers.Dense(_neurons[n],activation=\"sigmoid\"))\n",
    "\n",
    "        self.model.add(keras.layers.Dense(label_count, activation='softmax'))\n",
    "        \n",
    "        self.id = id \n",
    "        self.log_dir = base_log_dir+str(id)+\"/\"\n",
    "        \n",
    "            \n",
    "    def compile(self,_optimizer='adam',_loss='sparse_categorical_crossentropy', _metrics=[\"accuracy\"]):\n",
    "        if not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir)\n",
    "        else:\n",
    "            shutil.rmtree(self.log_dir, ignore_errors=True)\n",
    "            os.makedirs(self.log_dir)\n",
    "        self.model.compile(optimizer=_optimizer, loss=_loss,metrics=_metrics)\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=self.log_dir, histogram_freq=1)\n",
    "        self.tensorboard_callback = tensorboard_callback\n",
    "        \n",
    "        self.optimizer = _optimizer\n",
    "        self.loss = _loss \n",
    "        self.metrics = _metrics\n",
    "        \n",
    "    def fit(self,**argu):\n",
    "        self.model.fit(**argu)\n",
    "        \n",
    "        _text_log_dir = self.log_dir+\"Parameter Logs\"\n",
    "        \n",
    "        if not os.path.exists(_text_log_dir):\n",
    "            os.makedirs(_text_log_dir)\n",
    "        else:\n",
    "            shutil.rmtree(_text_log_dir, ignore_errors=True)\n",
    "            os.makedirs(_text_log_dir)\n",
    "            \n",
    "        file_writer = tf.summary.create_file_writer(_text_log_dir)\n",
    "        self.optimizer = \"adam\"\n",
    "        argu[\"optimizer\"] = self.optimizer\n",
    "        argu[\"loss\"] = self.loss\n",
    "        argu[\"metrics\"] = self.metrics\n",
    "        \n",
    "        \n",
    "        argu[\"Test loss\"],argu[\"Test accuracy\"] = self.model.evaluate(X_test,Y_test)        \n",
    "        \n",
    "        del argu[\"x\"]\n",
    "        del argu[\"y\"]\n",
    "        del argu [\"validation_data\"]\n",
    "        del argu[\"callbacks\"]\n",
    "        \n",
    "        index = 0\n",
    "        for key in argu:\n",
    "            with file_writer.as_default():                            \n",
    "                tf.summary.text(\"Parameter report: \"+str(key), str(key) + \" : \" +str(argu[key]) , step=index)\n",
    "                index+=1    \n",
    "                \n",
    "        \n",
    "        with open(self.log_dir + \"json_report.json\", 'w') as outfile:\n",
    "            json.dump(argu, outfile)\n",
    "        self.save()\n",
    "        self.plot()\n",
    "        \n",
    "            \n",
    "    def save(self):\n",
    "        self.model.save(self.log_dir+\"model.h5\")\n",
    "        \n",
    "    def plot(self):\n",
    "        keras.utils.plot_model(self.model,to_file=self.log_dir+\"graph.png\",show_shapes=True,expand_nested=True,show_layer_activations=True,show_dtype=True,show_layer_names=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MLPs on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding optimal parameters for # layers & # units(Keras Tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 07s]\n",
      "val_accuracy: 0.8766999244689941\n",
      "\n",
      "Best val_accuracy So Far: 0.8966454863548279\n",
      "Total elapsed time: 01h 18m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 192\n",
      "units_1: 576\n",
      "units_2: 128\n",
      "units_3: 1024\n",
      "units_4: 256\n",
      "units_5: 640\n",
      "Score: 0.8966454863548279\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 704\n",
      "units_1: 384\n",
      "units_2: 512\n",
      "units_3: 320\n",
      "units_4: 960\n",
      "units_5: 832\n",
      "Score: 0.893925666809082\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 576\n",
      "units_1: 384\n",
      "units_2: 512\n",
      "units_3: 384\n",
      "units_4: 640\n",
      "units_5: 384\n",
      "Score: 0.893925666809082\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 448\n",
      "units_1: 128\n",
      "units_2: 192\n",
      "units_3: 576\n",
      "units_4: 192\n",
      "units_5: 512\n",
      "Score: 0.8921124339103699\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 448\n",
      "units_1: 512\n",
      "units_2: 256\n",
      "units_3: 320\n",
      "units_4: 64\n",
      "units_5: 576\n",
      "Score: 0.8921124339103699\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 832\n",
      "units_1: 512\n",
      "units_2: 256\n",
      "units_3: 128\n",
      "units_4: 640\n",
      "units_5: 640\n",
      "Score: 0.8921124339103699\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 384\n",
      "units_1: 64\n",
      "units_2: 64\n",
      "Score: 0.8902992010116577\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 320\n",
      "units_1: 960\n",
      "units_2: 192\n",
      "units_3: 320\n",
      "units_4: 512\n",
      "units_5: 128\n",
      "Score: 0.8902992010116577\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 320\n",
      "units_1: 768\n",
      "units_2: 640\n",
      "units_3: 640\n",
      "units_4: 512\n",
      "units_5: 448\n",
      "Score: 0.8902992010116577\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 832\n",
      "units_1: 704\n",
      "units_2: 832\n",
      "units_3: 640\n",
      "units_4: 896\n",
      "units_5: 128\n",
      "Score: 0.8893925547599792\n"
     ]
    }
   ],
   "source": [
    "def ModelBuilder(hyperparameter):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    for i in range(hyperparameter.Int(\"num_layers\", 1, 6)):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units=hyperparameter.Int(f\"units_{i}\", min_value=64, max_value=1024, step=64),\n",
    "                activation= \"sigmoid\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(keras.layers.Dense(6, activation=\"softmax\"))    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(ModelBuilder,objective='val_accuracy',max_trials=30)\n",
    "tuner.search(X_train, Y_train, epochs=50, validation_data=(X_valid, Y_valid))\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding optimal parameter for LR (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.5>\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 6.8472 - accuracy: 0.1822\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 2.0300 - accuracy: 0.1805\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 1.8171 - accuracy: 0.1822\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8585\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7988\n"
     ]
    }
   ],
   "source": [
    "LRs = [0.5,0.1,0.01,0.001,0.0001]\n",
    "\n",
    "for lr in LRs:\n",
    "    optimizer = tf.keras.optimizers.Adam(lr)\n",
    "    time.sleep(5)\n",
    "    optimizer.learning_rate.assign(lr)\n",
    "    print(optimizer.learning_rate)\n",
    "    model = SequentialANN((X_train.shape[1],X_train.shape[1]),6,[1024,128],\"Extracted featrue - LR {0}\".format(lr))\n",
    "    model.compile(optimizer)\n",
    "    model.fit(x=X_train, \n",
    "                    y=Y_train, \n",
    "                    batch_size=48,\n",
    "                    epochs=100, \n",
    "                    verbose=0,\n",
    "                    validation_data=(X_valid, Y_valid),callbacks=[model.tensorboard_callback])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training optimal MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 10ms/step - loss: 1.6010 - accuracy: 0.2957 - val_loss: 1.1875 - val_accuracy: 0.3744\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0716 - accuracy: 0.4770 - val_loss: 0.9496 - val_accuracy: 0.5014\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.8883 - accuracy: 0.5482 - val_loss: 0.8031 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.7803 - accuracy: 0.6089 - val_loss: 0.7683 - val_accuracy: 0.5984\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.7131 - accuracy: 0.6657 - val_loss: 0.6905 - val_accuracy: 0.6646\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.6633 - accuracy: 0.6918 - val_loss: 0.6313 - val_accuracy: 0.7452\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.6106 - accuracy: 0.7248 - val_loss: 0.5945 - val_accuracy: 0.7189\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.5926 - accuracy: 0.7332 - val_loss: 0.5727 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.5477 - accuracy: 0.7592 - val_loss: 0.5459 - val_accuracy: 0.7743\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.5189 - accuracy: 0.7790 - val_loss: 0.5117 - val_accuracy: 0.7579\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.4805 - accuracy: 0.7932 - val_loss: 0.4606 - val_accuracy: 0.8024\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.4395 - accuracy: 0.8144 - val_loss: 0.4268 - val_accuracy: 0.8323\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.4341 - accuracy: 0.8161 - val_loss: 0.4392 - val_accuracy: 0.8024\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4010 - accuracy: 0.8310 - val_loss: 0.4102 - val_accuracy: 0.8250\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.3828 - accuracy: 0.8377 - val_loss: 0.3567 - val_accuracy: 0.8522\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3817 - accuracy: 0.8373 - val_loss: 0.3575 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3663 - accuracy: 0.8424 - val_loss: 0.3565 - val_accuracy: 0.8468\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.3537 - accuracy: 0.8483 - val_loss: 0.3331 - val_accuracy: 0.8531\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3424 - accuracy: 0.8491 - val_loss: 0.3363 - val_accuracy: 0.8658\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3451 - accuracy: 0.8542 - val_loss: 0.3943 - val_accuracy: 0.8386\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.3411 - accuracy: 0.8491 - val_loss: 0.3511 - val_accuracy: 0.8549\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3308 - accuracy: 0.8573 - val_loss: 0.3591 - val_accuracy: 0.8486\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3362 - accuracy: 0.8517 - val_loss: 0.3201 - val_accuracy: 0.8604\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3235 - accuracy: 0.8603 - val_loss: 0.3021 - val_accuracy: 0.8649\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3188 - accuracy: 0.8619 - val_loss: 0.2893 - val_accuracy: 0.8776\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3134 - accuracy: 0.8653 - val_loss: 0.3565 - val_accuracy: 0.8468\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3103 - accuracy: 0.8625 - val_loss: 0.2954 - val_accuracy: 0.8722\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.3053 - accuracy: 0.8637 - val_loss: 0.2904 - val_accuracy: 0.8740\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3020 - accuracy: 0.8678 - val_loss: 0.2881 - val_accuracy: 0.8785\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.2966 - accuracy: 0.8701 - val_loss: 0.2989 - val_accuracy: 0.8749\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2956 - accuracy: 0.8741 - val_loss: 0.2896 - val_accuracy: 0.8767\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.2943 - accuracy: 0.8717 - val_loss: 0.2719 - val_accuracy: 0.8849\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2927 - accuracy: 0.8713 - val_loss: 0.2806 - val_accuracy: 0.8840\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2880 - accuracy: 0.8737 - val_loss: 0.2778 - val_accuracy: 0.8758\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2895 - accuracy: 0.8704 - val_loss: 0.2742 - val_accuracy: 0.8830\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2859 - accuracy: 0.8766 - val_loss: 0.2708 - val_accuracy: 0.8830\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2844 - accuracy: 0.8723 - val_loss: 0.2862 - val_accuracy: 0.8840\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2801 - accuracy: 0.8774 - val_loss: 0.2794 - val_accuracy: 0.8830\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2799 - accuracy: 0.8755 - val_loss: 0.2692 - val_accuracy: 0.8840\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2764 - accuracy: 0.8774 - val_loss: 0.2822 - val_accuracy: 0.8731\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2740 - accuracy: 0.8777 - val_loss: 0.2672 - val_accuracy: 0.8894\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2849 - accuracy: 0.8758 - val_loss: 0.2729 - val_accuracy: 0.8840\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2770 - accuracy: 0.8773 - val_loss: 0.3024 - val_accuracy: 0.8749\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2744 - accuracy: 0.8784 - val_loss: 0.2619 - val_accuracy: 0.8930\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2680 - accuracy: 0.8785 - val_loss: 0.2806 - val_accuracy: 0.8840\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.2770 - accuracy: 0.8789 - val_loss: 0.3008 - val_accuracy: 0.8740\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2733 - accuracy: 0.8814 - val_loss: 0.2706 - val_accuracy: 0.8921\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2773 - accuracy: 0.8758 - val_loss: 0.2599 - val_accuracy: 0.8912\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2772 - accuracy: 0.8777 - val_loss: 0.2609 - val_accuracy: 0.8903\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2786 - accuracy: 0.8798 - val_loss: 0.2757 - val_accuracy: 0.8776\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2725 - accuracy: 0.8798 - val_loss: 0.2861 - val_accuracy: 0.8749\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2695 - accuracy: 0.8805 - val_loss: 0.2608 - val_accuracy: 0.8876\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2636 - accuracy: 0.8856 - val_loss: 0.2500 - val_accuracy: 0.8930\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2616 - accuracy: 0.8827 - val_loss: 0.2811 - val_accuracy: 0.8830\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2761 - accuracy: 0.8763 - val_loss: 0.2541 - val_accuracy: 0.8921\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2590 - accuracy: 0.8837 - val_loss: 0.2549 - val_accuracy: 0.8930\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2614 - accuracy: 0.8851 - val_loss: 0.2602 - val_accuracy: 0.8957\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.2544 - accuracy: 0.8870 - val_loss: 0.2481 - val_accuracy: 0.8966\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2724 - accuracy: 0.8790 - val_loss: 0.2504 - val_accuracy: 0.8912\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2683 - accuracy: 0.8841 - val_loss: 0.2502 - val_accuracy: 0.8858\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2668 - accuracy: 0.8800 - val_loss: 0.2716 - val_accuracy: 0.8885\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2618 - accuracy: 0.8833 - val_loss: 0.2985 - val_accuracy: 0.8830\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2568 - accuracy: 0.8883 - val_loss: 0.2684 - val_accuracy: 0.8903\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2716 - accuracy: 0.8819 - val_loss: 0.2832 - val_accuracy: 0.8803\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2595 - accuracy: 0.8838 - val_loss: 0.2408 - val_accuracy: 0.8994\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2613 - accuracy: 0.8840 - val_loss: 0.2503 - val_accuracy: 0.8985\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2570 - accuracy: 0.8846 - val_loss: 0.2452 - val_accuracy: 0.8985\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.2537 - accuracy: 0.8885 - val_loss: 0.2603 - val_accuracy: 0.8921\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2634 - accuracy: 0.8832 - val_loss: 0.2870 - val_accuracy: 0.8876\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.2563 - accuracy: 0.8880 - val_loss: 0.2696 - val_accuracy: 0.8912\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2489 - accuracy: 0.8897 - val_loss: 0.2438 - val_accuracy: 0.8921\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2599 - accuracy: 0.8841 - val_loss: 0.3131 - val_accuracy: 0.8694\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.2511 - accuracy: 0.8912 - val_loss: 0.2621 - val_accuracy: 0.8921\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2547 - accuracy: 0.8883 - val_loss: 0.2461 - val_accuracy: 0.8912\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2558 - accuracy: 0.8862 - val_loss: 0.2624 - val_accuracy: 0.8939\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2518 - accuracy: 0.8889 - val_loss: 0.2531 - val_accuracy: 0.8921\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2483 - accuracy: 0.8886 - val_loss: 0.2531 - val_accuracy: 0.8921\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2620 - accuracy: 0.8825 - val_loss: 0.2606 - val_accuracy: 0.8912\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.2536 - accuracy: 0.8888 - val_loss: 0.2447 - val_accuracy: 0.8957\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2581 - accuracy: 0.8888 - val_loss: 0.2667 - val_accuracy: 0.8849\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2485 - accuracy: 0.8886 - val_loss: 0.2750 - val_accuracy: 0.8912\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2545 - accuracy: 0.8883 - val_loss: 0.2563 - val_accuracy: 0.8921\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2508 - accuracy: 0.8846 - val_loss: 0.2614 - val_accuracy: 0.8821\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2493 - accuracy: 0.8875 - val_loss: 0.2521 - val_accuracy: 0.8948\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2509 - accuracy: 0.8897 - val_loss: 0.2403 - val_accuracy: 0.8985\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2463 - accuracy: 0.8883 - val_loss: 0.2659 - val_accuracy: 0.8785\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2501 - accuracy: 0.8891 - val_loss: 0.2357 - val_accuracy: 0.9012\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2502 - accuracy: 0.8877 - val_loss: 0.2585 - val_accuracy: 0.8921\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2506 - accuracy: 0.8910 - val_loss: 0.2469 - val_accuracy: 0.8930\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2528 - accuracy: 0.8891 - val_loss: 0.2626 - val_accuracy: 0.8921\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2481 - accuracy: 0.8905 - val_loss: 0.2488 - val_accuracy: 0.8894\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2413 - accuracy: 0.8937 - val_loss: 0.2615 - val_accuracy: 0.8894\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2416 - accuracy: 0.8920 - val_loss: 0.2685 - val_accuracy: 0.8840\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2564 - accuracy: 0.8880 - val_loss: 0.2440 - val_accuracy: 0.8948\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.2557 - accuracy: 0.8846 - val_loss: 0.2679 - val_accuracy: 0.8858\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2522 - accuracy: 0.8878 - val_loss: 0.3207 - val_accuracy: 0.8631\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2502 - accuracy: 0.8878 - val_loss: 0.2531 - val_accuracy: 0.9003\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2418 - accuracy: 0.8910 - val_loss: 0.2368 - val_accuracy: 0.8994\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2443 - accuracy: 0.8913 - val_loss: 0.2382 - val_accuracy: 0.8985\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2499 - accuracy: 0.8875 - val_loss: 0.2508 - val_accuracy: 0.8948\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "model = SequentialANN((X_train.shape[1],X_train.shape[2]),6,[1024,128],\"Main-Extracted-Features\")\n",
    "model.compile()\n",
    "model.fit(x=X_train, \n",
    "                y=Y_train, \n",
    "                epochs=100, \n",
    "                verbose=1,\n",
    "                validation_data=(X_valid, Y_valid),callbacks=[model.tensorboard_callback])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CalculateMetricsAndPlot(Y_test,np.argmax(model.model.predict(X_test), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f58f5e3d824a28f35e64a3b79d7f63edde6993a3dcc3aa79d0be3205de7b8a2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
