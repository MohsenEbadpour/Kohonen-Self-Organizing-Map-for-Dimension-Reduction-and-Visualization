{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from statistics import mode\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,25)\n",
    "cmap = plt.get_cmap(\"Set2\")\n",
    "Colors = np.array(cmap.colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./UCI HAR Dataset/train/X_train.txt\",header=None,delim_whitespace=True).to_numpy()\n",
    "X_test = pd.read_csv(\"./UCI HAR Dataset/test/X_test.txt\",header=None,delim_whitespace=True).to_numpy()\n",
    "\n",
    "Y_train = pd.read_csv(\"./UCI HAR Dataset/train/y_train.txt\",header=None,delim_whitespace=True).to_numpy()\n",
    "Y_test = pd.read_csv(\"./UCI HAR Dataset/test/y_test.txt\",header=None,delim_whitespace=True).to_numpy()\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.15,stratify=Y_train)\n",
    "\n",
    "\n",
    "Total_X = np.concatenate((X_valid, X_train,X_test), axis=0)\n",
    "Total_Y = np.concatenate((Y_valid, Y_train,Y_test), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom SOM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSOM : \n",
    "    \"\"\"Storing size of SOM grid with feature vector len and Learning rate, radius\"\"\"\n",
    "    def __init__(self,grid_size=(10,10),features_count=561,lr=0.01,radius=None):\n",
    "        self.grid_size = grid_size \n",
    "        self.lr_0 = lr\n",
    "        self.features_count = features_count \n",
    "        if radius is None : \n",
    "            radius = min(grid_size)\n",
    "        self.radius_0 = radius\n",
    "        self.reset()\n",
    "        \n",
    "    \"\"\"Resting network training logs\"\"\"\n",
    "    def reset(self):\n",
    "        self.lr = self.lr_0\n",
    "        self.radius = self.radius_0\n",
    "        self.w_map_0 = np.random.RandomState(0).random((self.grid_size[0],self.grid_size[1],self.features_count)).astype(float)\n",
    "        self.w_map = self.w_map_0.copy()\n",
    "        self.dead_neurons = []\n",
    "        self.distance_mean = []\n",
    "        self.loss = []\n",
    "        \n",
    "    \"\"\"Train SOM network\"\"\"\n",
    "    def train(self,X,Ite,lr_decay=1,ErrorThresh=10**-20):\n",
    "        self.reset()\n",
    "        self.Ite = Ite\n",
    "        non_deads =  np.zeros(self.grid_size)\n",
    "        for ite in range(Ite):\n",
    "            pre_w_map = self.w_map.copy()\n",
    "            shuffled_index =  random.sample(list(range(X.shape[0])), X.shape[0])\n",
    "            distance_mean = np.zeros_like(X[0])\n",
    "            for index in range(X.shape[0]):\n",
    "                x_sample = X[shuffled_index[index],:]\n",
    "                winner = self.get_winner(x_sample)\n",
    "                non_deads[winner[0],winner[1]] += 1 \n",
    "                neighbour_mask = self.get_neighbour_mask(winner)\n",
    "                self.w_map_update(x_sample,neighbour_mask,X.shape[0])\n",
    "\n",
    "                winner = self.w_map[winner[0],winner[1]].copy()\n",
    "                distance_mean += np.abs(x_sample-winner)\n",
    "            \n",
    "\n",
    "            deads = self.grid_size[0]*self.grid_size[1] - np.count_nonzero(non_deads) \n",
    "            self.dead_neurons.append(deads)\n",
    "                        \n",
    "            distance_mean /= X.shape[0]    \n",
    "            self.distance_mean.append(distance_mean.mean())    \n",
    "\n",
    "            if (ite/(Ite))*lr_decay > 0 :\n",
    "                self.lr = self.lr_0 * (1-(ite/(Ite))*lr_decay)\n",
    "                self.radius = self.radius_0 * (1-(ite/(Ite)))\n",
    "            \n",
    "            self.loss.append(np.linalg.norm(pre_w_map - self.w_map))\n",
    "            \n",
    "\n",
    "            if ite%5 == 0 or ite == Ite-1:\n",
    "                print(f\"Ite: {ite}, Loss: {self.loss[-1]:.4f}, lr: {self.lr:.4f},R: {self.radius}\")\n",
    "                     \n",
    "            if self.loss[-1] <= ErrorThresh :\n",
    "                print(\"Converged early in iteration #{0}\".format(ite))\n",
    "                return \n",
    "     \n",
    "    \"\"\"Visualize Clusters on grid of network\"\"\"       \n",
    "    def visualize(self, X, Y):    \n",
    "        predict = {}    \n",
    "        for index in range(len(X)):\n",
    "            x_sample = X[index, :]\n",
    "            winner = self.get_winner(x_sample)\n",
    "            if winner in predict :\n",
    "                predict[winner].append(Y[index][0])\n",
    "            else:\n",
    "                predict[winner] = [Y[index][0]]\n",
    "        img = np.zeros((self.grid_size[0],self.grid_size[1],3))\n",
    "        img.fill(200)\n",
    "        global Colors\n",
    "        for i in range(self.grid_size[0]):\n",
    "            for j in range(self.grid_size[1]):\n",
    "                if tuple([i,j]) in predict:\n",
    "                    color_index =  mode(predict[tuple([i,j])]) \n",
    "                    img[i,j] = Colors[color_index]    \n",
    "                \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Cluster Vizualization | MIte:{0}/LR:{1} | Size:({2},{3}) | R:{4}\".format(self.Ite,self.lr_0,self.grid_size[0],self.grid_size[1],self.radius_0))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    \"\"\"Calculate U-Matrix, visualize and return it\"\"\"\n",
    "    def get_u_matrix(self,show=False):\n",
    "        u_matrix = np.zeros(self.grid_size)\n",
    "        for i in range(self.grid_size[0]):\n",
    "            for j in range(self.grid_size[1]):\n",
    "                n = 0\n",
    "                for ri in range(-1, 2):\n",
    "                    for rj in range(-1, 2):\n",
    "                        if 0 <= i + ri < self.grid_size[0] and 0 <= j + rj < self.grid_size[1]:\n",
    "                            if np.sqrt(ri**2 + rj**2) <= 1 :\n",
    "                                u_matrix[i,j] += (np.linalg.norm(self.w_map[i,j] - self.w_map[ri,rj]))\n",
    "                                n +=1\n",
    "                            \n",
    "                u_matrix[i,j] /= n\n",
    "        if show :\n",
    "            sns.heatmap(u_matrix,annot=True,fmt=\".3f\",linewidths=2, linecolor='white',cmap=\"viridis\") \n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"U-Matrix of SOM - MIteration:{0}/LearningRate:{1}\".format(self.Ite,self.lr_0))\n",
    "            \n",
    "        return u_matrix\n",
    "            \n",
    "    \"\"\"Transform a entire dataset to new feature space\"\"\"\n",
    "    def dataset_transform(self,X):\n",
    "        new_x = np.zeros((X.shape[0],self.grid_size[0],self.grid_size[1]))\n",
    "        for index in range(X.shape[0]):\n",
    "            new_x[index]= self.feature_transform(X[index])\n",
    "        return new_x             \n",
    "      \n",
    "    \"\"\"Transform single sample to new space\"\"\"      \n",
    "    def feature_transform(self, x,show=False):\n",
    "        rep_x = np.tile(x, (self.w_map.shape[0], self.w_map.shape[1], 1))\n",
    "        dists = np.sum((self.w_map - rep_x) ** 2, axis=2)\n",
    "        if show :\n",
    "            plt.imshow(1/(1+dists),cmap=\"cool\")\n",
    "            plt.title(\"Feature Extracted map - MIteration:{0}/LearningRate:{1}\".format(self.Ite,self.lr_0))\n",
    "        return 1/(1+dists)\n",
    "    \n",
    "    \"\"\"Calculate winner neuron entire grid\"\"\"        \n",
    "    def get_winner(self,x_sample):   \n",
    "        rep_x = np.tile(x_sample, (self.w_map.shape[0], self.w_map.shape[1], 1))\n",
    "        dists = np.sum((self.w_map - rep_x) ** 2, axis=2)\n",
    "        winner = np.unravel_index(np.argmin(dists, axis=None), shape=dists.shape)\n",
    "        return winner\n",
    "    \n",
    "    \"\"\"Get a mask that neighbours of winner included with their coef\"\"\"\n",
    "    def get_neighbour_mask(self,winner_index):\n",
    "        mask = np.zeros(self.grid_size)\n",
    "        mask[winner_index[0],winner_index[1]] = 1\n",
    "        Radius = int(self.radius)\n",
    "        for ri in range(-Radius, Radius+1):\n",
    "            for rj in range(-Radius, Radius+1):\n",
    "                if 0 <= winner_index[0] + ri < self.w_map.shape[0] and 0 <= winner_index[1] + rj < self.w_map.shape[1]:\n",
    "                    if np.sqrt(ri**2 + rj**2) > Radius :\n",
    "                        mask[winner_index[0] + ri, winner_index[1] + rj] = 0                     \n",
    "                    else:\n",
    "                        mask[winner_index[0] + ri, winner_index[1] + rj] = 1/(1+np.sqrt(ri**2 + rj**2))           \n",
    "        return mask \n",
    "    \n",
    "    \"\"\"Update weights of map during train based on neighbours mask of winner neuron\"\"\"\n",
    "    def w_map_update(self,x_sample,neighbour_mask,X_len):\n",
    "        neighbour_mask = np.repeat(neighbour_mask[:,:,np.newaxis],self.w_map.shape[2],axis=2)\n",
    "        x_repeat = np.tile(x_sample, (self.w_map.shape[0], self.w_map.shape[1], 1))\n",
    "        Delta = x_repeat - self.w_map\n",
    "        self.w_map = self.w_map + (self.lr/X_len) * np.multiply(neighbour_mask, Delta)\n",
    "                \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main: Training SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ite: 0, Loss: 39.9921, lr: 0.8000,R: 5\n",
      "Ite: 5, Loss: 9.3588, lr: 0.7989,R: 4.99375\n",
      "Ite: 10, Loss: 6.5624, lr: 0.7978,R: 4.987500000000001\n",
      "Ite: 15, Loss: 4.6875, lr: 0.7967,R: 4.98125\n",
      "Ite: 20, Loss: 2.6376, lr: 0.7956,R: 4.975\n",
      "Ite: 25, Loss: 2.1322, lr: 0.7945,R: 4.96875\n",
      "Ite: 30, Loss: 2.5664, lr: 0.7934,R: 4.9625\n",
      "Ite: 35, Loss: 2.7047, lr: 0.7923,R: 4.95625\n",
      "Ite: 40, Loss: 2.8242, lr: 0.7912,R: 4.95\n",
      "Ite: 45, Loss: 2.9552, lr: 0.7901,R: 4.94375\n",
      "Ite: 50, Loss: 2.5284, lr: 0.7890,R: 4.9375\n",
      "Ite: 55, Loss: 2.2664, lr: 0.7879,R: 4.9312499999999995\n",
      "Ite: 60, Loss: 2.1153, lr: 0.7868,R: 4.925\n",
      "Ite: 65, Loss: 1.9591, lr: 0.7857,R: 4.91875\n",
      "Ite: 70, Loss: 1.7518, lr: 0.7846,R: 4.9125000000000005\n",
      "Ite: 75, Loss: 1.6365, lr: 0.7835,R: 4.90625\n",
      "Ite: 80, Loss: 1.4330, lr: 0.7824,R: 4.9\n",
      "Ite: 85, Loss: 1.2817, lr: 0.7813,R: 4.89375\n",
      "Ite: 90, Loss: 1.1650, lr: 0.7802,R: 4.8875\n",
      "Ite: 95, Loss: 1.1045, lr: 0.7791,R: 4.88125\n",
      "Ite: 100, Loss: 1.0073, lr: 0.7780,R: 4.875\n",
      "Ite: 105, Loss: 0.8972, lr: 0.7769,R: 4.86875\n",
      "Ite: 110, Loss: 0.7817, lr: 0.7758,R: 4.8625\n",
      "Ite: 115, Loss: 0.6768, lr: 0.7747,R: 4.856249999999999\n",
      "Ite: 120, Loss: 0.5862, lr: 0.7736,R: 4.85\n",
      "Ite: 125, Loss: 0.4853, lr: 0.7725,R: 4.84375\n",
      "Ite: 130, Loss: 0.3935, lr: 0.7714,R: 4.8375\n",
      "Ite: 135, Loss: 0.3298, lr: 0.7703,R: 4.831250000000001\n",
      "Ite: 140, Loss: 0.2622, lr: 0.7692,R: 4.825\n",
      "Ite: 145, Loss: 0.2278, lr: 0.7681,R: 4.81875\n",
      "Ite: 150, Loss: 0.1940, lr: 0.7670,R: 4.8125\n",
      "Ite: 155, Loss: 0.1610, lr: 0.7659,R: 4.80625\n",
      "Ite: 160, Loss: 0.1329, lr: 0.7648,R: 4.8\n",
      "Ite: 165, Loss: 0.1209, lr: 0.7637,R: 4.79375\n",
      "Ite: 170, Loss: 0.1060, lr: 0.7626,R: 4.7875\n",
      "Ite: 175, Loss: 0.0969, lr: 0.7615,R: 4.78125\n",
      "Ite: 180, Loss: 0.0921, lr: 0.7604,R: 4.7749999999999995\n",
      "Ite: 185, Loss: 0.0882, lr: 0.7593,R: 4.76875\n",
      "Ite: 190, Loss: 0.0765, lr: 0.7582,R: 4.7625\n",
      "Ite: 195, Loss: 0.0774, lr: 0.7571,R: 4.7562500000000005\n",
      "Ite: 200, Loss: 0.0641, lr: 0.7560,R: 4.75\n",
      "Ite: 205, Loss: 0.0528, lr: 0.7549,R: 4.74375\n",
      "Ite: 210, Loss: 0.0510, lr: 0.7538,R: 4.7375\n",
      "Ite: 215, Loss: 0.0432, lr: 0.7527,R: 4.73125\n",
      "Ite: 220, Loss: 0.0337, lr: 0.7516,R: 4.725\n",
      "Ite: 225, Loss: 0.0277, lr: 0.7505,R: 4.71875\n",
      "Ite: 230, Loss: 0.0243, lr: 0.7494,R: 4.7125\n",
      "Ite: 235, Loss: 0.0229, lr: 0.7483,R: 4.70625\n",
      "Ite: 240, Loss: 0.0199, lr: 0.7472,R: 4.699999999999999\n",
      "Ite: 245, Loss: 0.0257, lr: 0.7461,R: 4.69375\n",
      "Ite: 250, Loss: 0.0240, lr: 0.7450,R: 4.6875\n",
      "Ite: 255, Loss: 0.0196, lr: 0.7439,R: 4.68125\n",
      "Ite: 260, Loss: 0.0174, lr: 0.7428,R: 4.675000000000001\n",
      "Ite: 265, Loss: 0.0118, lr: 0.7417,R: 4.66875\n",
      "Ite: 270, Loss: 0.0122, lr: 0.7406,R: 4.6625\n",
      "Ite: 275, Loss: 0.0124, lr: 0.7395,R: 4.65625\n",
      "Ite: 280, Loss: 0.0120, lr: 0.7384,R: 4.6499999999999995\n",
      "Ite: 285, Loss: 0.0098, lr: 0.7373,R: 4.64375\n",
      "Ite: 290, Loss: 0.0100, lr: 0.7362,R: 4.6375\n",
      "Ite: 295, Loss: 0.0077, lr: 0.7351,R: 4.63125\n",
      "Ite: 300, Loss: 0.0074, lr: 0.7340,R: 4.625\n",
      "Ite: 305, Loss: 0.0069, lr: 0.7329,R: 4.6187499999999995\n",
      "Ite: 310, Loss: 0.0071, lr: 0.7318,R: 4.6125\n",
      "Ite: 315, Loss: 0.0065, lr: 0.7307,R: 4.60625\n",
      "Ite: 320, Loss: 0.0061, lr: 0.7296,R: 4.6000000000000005\n",
      "Ite: 325, Loss: 0.0058, lr: 0.7285,R: 4.59375\n",
      "Ite: 330, Loss: 0.0047, lr: 0.7274,R: 4.5875\n",
      "Ite: 335, Loss: 0.0047, lr: 0.7263,R: 4.58125\n",
      "Ite: 340, Loss: 0.0063, lr: 0.7252,R: 4.575\n",
      "Ite: 345, Loss: 0.0049, lr: 0.7241,R: 4.5687500000000005\n",
      "Ite: 350, Loss: 0.0058, lr: 0.7230,R: 4.5625\n",
      "Ite: 355, Loss: 0.0057, lr: 0.7219,R: 4.55625\n",
      "Ite: 360, Loss: 0.0050, lr: 0.7208,R: 4.55\n",
      "Ite: 365, Loss: 0.0053, lr: 0.7197,R: 4.543749999999999\n",
      "Ite: 370, Loss: 0.0050, lr: 0.7186,R: 4.5375\n",
      "Ite: 375, Loss: 0.0046, lr: 0.7175,R: 4.53125\n",
      "Ite: 380, Loss: 0.0044, lr: 0.7164,R: 4.525\n",
      "Ite: 385, Loss: 0.0058, lr: 0.7153,R: 4.518750000000001\n",
      "Ite: 390, Loss: 0.0048, lr: 0.7142,R: 4.5125\n",
      "Ite: 395, Loss: 0.0053, lr: 0.7131,R: 4.50625\n",
      "Ite: 400, Loss: 0.0042, lr: 0.7120,R: 4.5\n",
      "Ite: 405, Loss: 0.0047, lr: 0.7109,R: 4.4937499999999995\n",
      "Ite: 410, Loss: 0.0041, lr: 0.7098,R: 4.4875\n",
      "Ite: 415, Loss: 0.0048, lr: 0.7087,R: 4.48125\n",
      "Ite: 420, Loss: 0.0045, lr: 0.7076,R: 4.475\n",
      "Ite: 425, Loss: 0.0042, lr: 0.7065,R: 4.46875\n",
      "Ite: 430, Loss: 0.0040, lr: 0.7054,R: 4.4624999999999995\n",
      "Ite: 435, Loss: 0.0050, lr: 0.7043,R: 4.45625\n",
      "Ite: 440, Loss: 0.0040, lr: 0.7032,R: 4.45\n",
      "Ite: 445, Loss: 0.0036, lr: 0.7021,R: 4.4437500000000005\n",
      "Ite: 450, Loss: 0.0038, lr: 0.7010,R: 4.4375\n",
      "Ite: 455, Loss: 0.0044, lr: 0.6999,R: 4.43125\n",
      "Ite: 460, Loss: 0.0040, lr: 0.6988,R: 4.425\n",
      "Ite: 465, Loss: 0.0048, lr: 0.6977,R: 4.41875\n",
      "Ite: 470, Loss: 0.0046, lr: 0.6966,R: 4.4125000000000005\n",
      "Ite: 475, Loss: 0.0056, lr: 0.6955,R: 4.40625\n",
      "Ite: 480, Loss: 0.0041, lr: 0.6944,R: 4.4\n",
      "Ite: 485, Loss: 0.0038, lr: 0.6933,R: 4.39375\n",
      "Ite: 490, Loss: 0.0043, lr: 0.6922,R: 4.387499999999999\n",
      "Ite: 495, Loss: 0.0037, lr: 0.6911,R: 4.38125\n",
      "Ite: 500, Loss: 0.0059, lr: 0.6900,R: 4.375\n",
      "Ite: 505, Loss: 0.0039, lr: 0.6889,R: 4.36875\n",
      "Ite: 510, Loss: 0.0049, lr: 0.6878,R: 4.362500000000001\n",
      "Ite: 515, Loss: 0.0042, lr: 0.6867,R: 4.35625\n",
      "Ite: 520, Loss: 0.0044, lr: 0.6856,R: 4.35\n",
      "Ite: 525, Loss: 0.0042, lr: 0.6845,R: 4.34375\n",
      "Ite: 530, Loss: 0.0046, lr: 0.6834,R: 4.3374999999999995\n",
      "Ite: 535, Loss: 0.0039, lr: 0.6823,R: 4.33125\n",
      "Ite: 540, Loss: 0.0040, lr: 0.6812,R: 4.325\n",
      "Ite: 545, Loss: 0.0046, lr: 0.6801,R: 4.31875\n",
      "Ite: 550, Loss: 0.0050, lr: 0.6790,R: 4.3125\n",
      "Ite: 555, Loss: 0.0039, lr: 0.6779,R: 4.3062499999999995\n",
      "Ite: 560, Loss: 0.0036, lr: 0.6768,R: 4.3\n",
      "Ite: 565, Loss: 0.0041, lr: 0.6757,R: 4.29375\n",
      "Ite: 570, Loss: 0.0041, lr: 0.6746,R: 4.2875000000000005\n",
      "Ite: 575, Loss: 0.0042, lr: 0.6735,R: 4.28125\n",
      "Ite: 580, Loss: 0.0045, lr: 0.6724,R: 4.275\n",
      "Ite: 585, Loss: 0.0042, lr: 0.6713,R: 4.26875\n",
      "Ite: 590, Loss: 0.0039, lr: 0.6702,R: 4.2625\n",
      "Ite: 595, Loss: 0.0032, lr: 0.6691,R: 4.2562500000000005\n",
      "Ite: 600, Loss: 0.0040, lr: 0.6680,R: 4.25\n",
      "Ite: 605, Loss: 0.0044, lr: 0.6669,R: 4.24375\n",
      "Ite: 610, Loss: 0.0032, lr: 0.6658,R: 4.2375\n",
      "Ite: 615, Loss: 0.0044, lr: 0.6647,R: 4.231249999999999\n",
      "Ite: 620, Loss: 0.0040, lr: 0.6636,R: 4.225\n",
      "Ite: 625, Loss: 0.0037, lr: 0.6625,R: 4.21875\n",
      "Ite: 630, Loss: 0.0035, lr: 0.6614,R: 4.2125\n",
      "Ite: 635, Loss: 0.0038, lr: 0.6603,R: 4.206250000000001\n",
      "Ite: 640, Loss: 0.0043, lr: 0.6592,R: 4.2\n",
      "Ite: 645, Loss: 0.0039, lr: 0.6581,R: 4.19375\n",
      "Ite: 650, Loss: 0.0037, lr: 0.6570,R: 4.1875\n",
      "Ite: 655, Loss: 0.0031, lr: 0.6559,R: 4.1812499999999995\n",
      "Ite: 660, Loss: 0.0038, lr: 0.6548,R: 4.175\n",
      "Ite: 665, Loss: 0.0037, lr: 0.6537,R: 4.16875\n",
      "Ite: 670, Loss: 0.0039, lr: 0.6526,R: 4.1625\n",
      "Ite: 675, Loss: 0.0036, lr: 0.6515,R: 4.15625\n",
      "Ite: 680, Loss: 0.0039, lr: 0.6504,R: 4.1499999999999995\n",
      "Ite: 685, Loss: 0.0035, lr: 0.6493,R: 4.14375\n",
      "Ite: 690, Loss: 0.0036, lr: 0.6482,R: 4.1375\n",
      "Ite: 695, Loss: 0.0041, lr: 0.6471,R: 4.1312500000000005\n",
      "Ite: 700, Loss: 0.0036, lr: 0.6460,R: 4.125\n",
      "Ite: 705, Loss: 0.0033, lr: 0.6449,R: 4.11875\n",
      "Ite: 710, Loss: 0.0043, lr: 0.6438,R: 4.1125\n",
      "Ite: 715, Loss: 0.0032, lr: 0.6427,R: 4.10625\n",
      "Ite: 720, Loss: 0.0043, lr: 0.6416,R: 4.1000000000000005\n",
      "Ite: 725, Loss: 0.0036, lr: 0.6405,R: 4.09375\n",
      "Ite: 730, Loss: 0.0032, lr: 0.6394,R: 4.0875\n",
      "Ite: 735, Loss: 0.0037, lr: 0.6383,R: 4.08125\n",
      "Ite: 740, Loss: 0.0042, lr: 0.6372,R: 4.074999999999999\n",
      "Ite: 745, Loss: 0.0039, lr: 0.6361,R: 4.06875\n",
      "Ite: 750, Loss: 0.0036, lr: 0.6350,R: 4.0625\n",
      "Ite: 755, Loss: 0.0030, lr: 0.6339,R: 4.05625\n",
      "Ite: 760, Loss: 0.0038, lr: 0.6328,R: 4.050000000000001\n",
      "Ite: 765, Loss: 0.0038, lr: 0.6317,R: 4.04375\n",
      "Ite: 770, Loss: 0.0036, lr: 0.6306,R: 4.0375\n",
      "Ite: 775, Loss: 0.0033, lr: 0.6295,R: 4.03125\n",
      "Ite: 780, Loss: 0.0033, lr: 0.6284,R: 4.0249999999999995\n",
      "Ite: 785, Loss: 0.0043, lr: 0.6273,R: 4.01875\n",
      "Ite: 790, Loss: 0.0032, lr: 0.6262,R: 4.0125\n",
      "Ite: 795, Loss: 0.0044, lr: 0.6251,R: 4.00625\n",
      "Ite: 800, Loss: 0.0032, lr: 0.6240,R: 4.0\n",
      "Ite: 805, Loss: 0.2966, lr: 0.6229,R: 3.99375\n",
      "Ite: 810, Loss: 0.2282, lr: 0.6218,R: 3.9875\n",
      "Ite: 815, Loss: 0.1728, lr: 0.6207,R: 3.98125\n",
      "Ite: 820, Loss: 0.1351, lr: 0.6196,R: 3.975\n",
      "Ite: 825, Loss: 0.1054, lr: 0.6185,R: 3.96875\n",
      "Ite: 830, Loss: 0.0848, lr: 0.6174,R: 3.9625\n",
      "Ite: 835, Loss: 0.0709, lr: 0.6163,R: 3.95625\n",
      "Ite: 840, Loss: 0.0592, lr: 0.6152,R: 3.95\n",
      "Ite: 845, Loss: 0.0497, lr: 0.6141,R: 3.9437500000000005\n",
      "Ite: 850, Loss: 0.0407, lr: 0.6130,R: 3.9375\n",
      "Ite: 855, Loss: 0.0325, lr: 0.6119,R: 3.93125\n",
      "Ite: 860, Loss: 0.0273, lr: 0.6108,R: 3.9250000000000003\n",
      "Ite: 865, Loss: 0.0222, lr: 0.6097,R: 3.9187499999999997\n",
      "Ite: 870, Loss: 0.0236, lr: 0.6086,R: 3.9124999999999996\n",
      "Ite: 875, Loss: 0.0201, lr: 0.6075,R: 3.90625\n",
      "Ite: 880, Loss: 0.0173, lr: 0.6064,R: 3.9000000000000004\n",
      "Ite: 885, Loss: 0.0166, lr: 0.6053,R: 3.8937500000000003\n",
      "Ite: 890, Loss: 0.0153, lr: 0.6042,R: 3.8874999999999997\n",
      "Ite: 895, Loss: 0.0132, lr: 0.6031,R: 3.88125\n",
      "Ite: 900, Loss: 0.0173, lr: 0.6020,R: 3.875\n",
      "Ite: 905, Loss: 0.0198, lr: 0.6009,R: 3.8687499999999995\n",
      "Ite: 910, Loss: 0.0197, lr: 0.5998,R: 3.8625\n",
      "Ite: 915, Loss: 0.0172, lr: 0.5987,R: 3.85625\n",
      "Ite: 920, Loss: 0.0164, lr: 0.5976,R: 3.85\n",
      "Ite: 925, Loss: 0.0166, lr: 0.5965,R: 3.84375\n",
      "Ite: 930, Loss: 0.0160, lr: 0.5954,R: 3.8375\n",
      "Ite: 935, Loss: 0.0161, lr: 0.5943,R: 3.83125\n",
      "Ite: 940, Loss: 0.0204, lr: 0.5932,R: 3.825\n",
      "Ite: 945, Loss: 0.0234, lr: 0.5921,R: 3.81875\n",
      "Ite: 950, Loss: 0.0346, lr: 0.5910,R: 3.8125\n",
      "Ite: 955, Loss: 0.0379, lr: 0.5899,R: 3.80625\n",
      "Ite: 960, Loss: 0.0372, lr: 0.5888,R: 3.8\n",
      "Ite: 965, Loss: 0.0362, lr: 0.5877,R: 3.79375\n",
      "Ite: 970, Loss: 0.0345, lr: 0.5866,R: 3.7875000000000005\n",
      "Ite: 975, Loss: 0.0278, lr: 0.5855,R: 3.78125\n",
      "Ite: 980, Loss: 0.0238, lr: 0.5844,R: 3.775\n",
      "Ite: 985, Loss: 0.0204, lr: 0.5833,R: 3.7687500000000003\n",
      "Ite: 990, Loss: 0.0188, lr: 0.5822,R: 3.7624999999999997\n",
      "Ite: 995, Loss: 0.0153, lr: 0.5811,R: 3.7562499999999996\n",
      "Ite: 1000, Loss: 0.0128, lr: 0.5800,R: 3.75\n",
      "Ite: 1005, Loss: 0.0113, lr: 0.5789,R: 3.7437500000000004\n",
      "Ite: 1010, Loss: 0.0134, lr: 0.5778,R: 3.7375000000000003\n",
      "Ite: 1015, Loss: 0.0109, lr: 0.5767,R: 3.73125\n",
      "Ite: 1020, Loss: 0.0114, lr: 0.5756,R: 3.725\n",
      "Ite: 1025, Loss: 0.0089, lr: 0.5745,R: 3.71875\n",
      "Ite: 1030, Loss: 0.0097, lr: 0.5734,R: 3.7124999999999995\n",
      "Ite: 1035, Loss: 0.0084, lr: 0.5723,R: 3.70625\n",
      "Ite: 1040, Loss: 0.0067, lr: 0.5712,R: 3.7\n",
      "Ite: 1045, Loss: 0.0059, lr: 0.5701,R: 3.69375\n",
      "Ite: 1050, Loss: 0.0046, lr: 0.5690,R: 3.6875\n",
      "Ite: 1055, Loss: 0.0040, lr: 0.5679,R: 3.6812500000000004\n",
      "Ite: 1060, Loss: 0.0044, lr: 0.5668,R: 3.675\n",
      "Ite: 1065, Loss: 0.0049, lr: 0.5657,R: 3.66875\n",
      "Ite: 1070, Loss: 0.0041, lr: 0.5646,R: 3.6624999999999996\n",
      "Ite: 1075, Loss: 0.0031, lr: 0.5635,R: 3.65625\n",
      "Ite: 1080, Loss: 0.0027, lr: 0.5624,R: 3.65\n",
      "Ite: 1085, Loss: 0.0039, lr: 0.5613,R: 3.64375\n",
      "Ite: 1090, Loss: 0.0054, lr: 0.5602,R: 3.6375\n",
      "Ite: 1095, Loss: 0.0065, lr: 0.5591,R: 3.6312500000000005\n",
      "Ite: 1100, Loss: 0.0053, lr: 0.5580,R: 3.625\n",
      "Ite: 1105, Loss: 0.0052, lr: 0.5569,R: 3.61875\n",
      "Ite: 1110, Loss: 0.0042, lr: 0.5558,R: 3.6125\n",
      "Ite: 1115, Loss: 0.0046, lr: 0.5547,R: 3.6062499999999997\n",
      "Ite: 1120, Loss: 0.0069, lr: 0.5536,R: 3.5999999999999996\n",
      "Ite: 1125, Loss: 0.0056, lr: 0.5525,R: 3.59375\n",
      "Ite: 1130, Loss: 0.0046, lr: 0.5514,R: 3.5875000000000004\n",
      "Ite: 1135, Loss: 0.0048, lr: 0.5503,R: 3.5812500000000003\n",
      "Ite: 1140, Loss: 0.0040, lr: 0.5492,R: 3.575\n",
      "Ite: 1145, Loss: 0.0036, lr: 0.5481,R: 3.56875\n",
      "Ite: 1150, Loss: 0.0031, lr: 0.5470,R: 3.5625\n",
      "Ite: 1155, Loss: 0.0029, lr: 0.5459,R: 3.5562499999999995\n",
      "Ite: 1160, Loss: 0.0023, lr: 0.5448,R: 3.55\n",
      "Ite: 1165, Loss: 0.0022, lr: 0.5437,R: 3.54375\n",
      "Ite: 1170, Loss: 0.0020, lr: 0.5426,R: 3.5375\n",
      "Ite: 1175, Loss: 0.0021, lr: 0.5415,R: 3.53125\n",
      "Ite: 1180, Loss: 0.0017, lr: 0.5404,R: 3.5250000000000004\n",
      "Ite: 1185, Loss: 0.0023, lr: 0.5393,R: 3.51875\n",
      "Ite: 1190, Loss: 0.0016, lr: 0.5382,R: 3.5125\n",
      "Ite: 1195, Loss: 0.0017, lr: 0.5371,R: 3.5062499999999996\n",
      "Ite: 1200, Loss: 0.0020, lr: 0.5360,R: 3.5\n",
      "Ite: 1205, Loss: 0.0017, lr: 0.5349,R: 3.49375\n",
      "Ite: 1210, Loss: 0.0020, lr: 0.5338,R: 3.4875\n",
      "Ite: 1215, Loss: 0.0018, lr: 0.5327,R: 3.48125\n",
      "Ite: 1220, Loss: 0.0018, lr: 0.5316,R: 3.4750000000000005\n",
      "Ite: 1225, Loss: 0.0019, lr: 0.5305,R: 3.46875\n",
      "Ite: 1230, Loss: 0.0018, lr: 0.5294,R: 3.4625\n",
      "Ite: 1235, Loss: 0.0017, lr: 0.5283,R: 3.45625\n",
      "Ite: 1240, Loss: 0.0018, lr: 0.5272,R: 3.4499999999999997\n",
      "Ite: 1245, Loss: 0.0021, lr: 0.5261,R: 3.4437499999999996\n",
      "Ite: 1250, Loss: 0.0018, lr: 0.5250,R: 3.4375\n",
      "Ite: 1255, Loss: 0.0017, lr: 0.5239,R: 3.4312500000000004\n",
      "Ite: 1260, Loss: 0.0020, lr: 0.5228,R: 3.4250000000000003\n",
      "Ite: 1265, Loss: 0.0016, lr: 0.5217,R: 3.41875\n",
      "Ite: 1270, Loss: 0.0016, lr: 0.5206,R: 3.4125\n",
      "Ite: 1275, Loss: 0.0018, lr: 0.5195,R: 3.40625\n",
      "Ite: 1280, Loss: 0.0017, lr: 0.5184,R: 3.3999999999999995\n",
      "Ite: 1285, Loss: 0.0018, lr: 0.5173,R: 3.39375\n",
      "Ite: 1290, Loss: 0.0017, lr: 0.5162,R: 3.3875\n",
      "Ite: 1295, Loss: 0.0017, lr: 0.5151,R: 3.38125\n",
      "Ite: 1300, Loss: 0.0016, lr: 0.5140,R: 3.375\n",
      "Ite: 1305, Loss: 0.0015, lr: 0.5129,R: 3.3687500000000004\n",
      "Ite: 1310, Loss: 0.0016, lr: 0.5118,R: 3.3625\n",
      "Ite: 1315, Loss: 0.0015, lr: 0.5107,R: 3.35625\n",
      "Ite: 1320, Loss: 0.0016, lr: 0.5096,R: 3.3499999999999996\n",
      "Ite: 1325, Loss: 0.0015, lr: 0.5085,R: 3.34375\n",
      "Ite: 1330, Loss: 0.0018, lr: 0.5074,R: 3.3375\n",
      "Ite: 1335, Loss: 0.0017, lr: 0.5063,R: 3.33125\n",
      "Ite: 1340, Loss: 0.0016, lr: 0.5052,R: 3.325\n",
      "Ite: 1345, Loss: 0.0016, lr: 0.5041,R: 3.3187500000000005\n",
      "Ite: 1350, Loss: 0.0016, lr: 0.5030,R: 3.3125\n",
      "Ite: 1355, Loss: 0.0015, lr: 0.5019,R: 3.30625\n",
      "Ite: 1360, Loss: 0.0015, lr: 0.5008,R: 3.3\n",
      "Ite: 1365, Loss: 0.0016, lr: 0.4997,R: 3.2937499999999997\n",
      "Ite: 1370, Loss: 0.0017, lr: 0.4986,R: 3.2874999999999996\n",
      "Ite: 1375, Loss: 0.0017, lr: 0.4975,R: 3.28125\n",
      "Ite: 1380, Loss: 0.0015, lr: 0.4964,R: 3.2750000000000004\n",
      "Ite: 1385, Loss: 0.0015, lr: 0.4953,R: 3.2687500000000003\n",
      "Ite: 1390, Loss: 0.0017, lr: 0.4942,R: 3.2625\n",
      "Ite: 1395, Loss: 0.0015, lr: 0.4931,R: 3.25625\n",
      "Ite: 1400, Loss: 0.0014, lr: 0.4920,R: 3.25\n",
      "Ite: 1405, Loss: 0.0015, lr: 0.4909,R: 3.2437499999999995\n",
      "Ite: 1410, Loss: 0.0016, lr: 0.4898,R: 3.2375\n",
      "Ite: 1415, Loss: 0.0017, lr: 0.4887,R: 3.23125\n",
      "Ite: 1420, Loss: 0.0015, lr: 0.4876,R: 3.225\n",
      "Ite: 1425, Loss: 0.0016, lr: 0.4865,R: 3.21875\n",
      "Ite: 1430, Loss: 0.0016, lr: 0.4854,R: 3.2125000000000004\n",
      "Ite: 1435, Loss: 0.0013, lr: 0.4843,R: 3.20625\n",
      "Ite: 1440, Loss: 0.0014, lr: 0.4832,R: 3.2\n",
      "Ite: 1445, Loss: 0.0016, lr: 0.4821,R: 3.1937499999999996\n",
      "Ite: 1450, Loss: 0.0014, lr: 0.4810,R: 3.1875\n",
      "Ite: 1455, Loss: 0.0013, lr: 0.4799,R: 3.18125\n",
      "Ite: 1460, Loss: 0.0014, lr: 0.4788,R: 3.175\n",
      "Ite: 1465, Loss: 0.0013, lr: 0.4777,R: 3.16875\n",
      "Ite: 1470, Loss: 0.0016, lr: 0.4766,R: 3.1625000000000005\n",
      "Ite: 1475, Loss: 0.0014, lr: 0.4755,R: 3.15625\n",
      "Ite: 1480, Loss: 0.0016, lr: 0.4744,R: 3.15\n",
      "Ite: 1485, Loss: 0.0014, lr: 0.4733,R: 3.14375\n",
      "Ite: 1490, Loss: 0.0014, lr: 0.4722,R: 3.1374999999999997\n",
      "Ite: 1495, Loss: 0.0014, lr: 0.4711,R: 3.1312499999999996\n",
      "Ite: 1500, Loss: 0.0015, lr: 0.4700,R: 3.125\n",
      "Ite: 1505, Loss: 0.0014, lr: 0.4689,R: 3.1187500000000004\n",
      "Ite: 1510, Loss: 0.0013, lr: 0.4678,R: 3.1125000000000003\n",
      "Ite: 1515, Loss: 0.0016, lr: 0.4667,R: 3.10625\n",
      "Ite: 1520, Loss: 0.0013, lr: 0.4656,R: 3.1\n",
      "Ite: 1525, Loss: 0.0014, lr: 0.4645,R: 3.09375\n",
      "Ite: 1530, Loss: 0.0013, lr: 0.4634,R: 3.0874999999999995\n",
      "Ite: 1535, Loss: 0.0013, lr: 0.4623,R: 3.08125\n",
      "Ite: 1540, Loss: 0.0014, lr: 0.4612,R: 3.075\n",
      "Ite: 1545, Loss: 0.0014, lr: 0.4601,R: 3.06875\n",
      "Ite: 1550, Loss: 0.0013, lr: 0.4590,R: 3.0625\n",
      "Ite: 1555, Loss: 0.0013, lr: 0.4579,R: 3.0562500000000004\n",
      "Ite: 1560, Loss: 0.0014, lr: 0.4568,R: 3.05\n",
      "Ite: 1565, Loss: 0.0012, lr: 0.4557,R: 3.04375\n",
      "Ite: 1570, Loss: 0.0013, lr: 0.4546,R: 3.0374999999999996\n",
      "Ite: 1575, Loss: 0.0012, lr: 0.4535,R: 3.03125\n",
      "Ite: 1580, Loss: 0.0012, lr: 0.4524,R: 3.025\n",
      "Ite: 1585, Loss: 0.0014, lr: 0.4513,R: 3.01875\n",
      "Ite: 1590, Loss: 0.0011, lr: 0.4502,R: 3.0125\n",
      "Ite: 1595, Loss: 0.0014, lr: 0.4491,R: 3.0062500000000005\n",
      "Ite: 1600, Loss: 0.0012, lr: 0.4480,R: 3.0\n",
      "Ite: 1605, Loss: 0.1628, lr: 0.4469,R: 2.99375\n",
      "Ite: 1610, Loss: 0.1457, lr: 0.4458,R: 2.9875\n",
      "Ite: 1615, Loss: 0.1312, lr: 0.4447,R: 2.9812499999999997\n",
      "Ite: 1620, Loss: 0.1182, lr: 0.4436,R: 2.9749999999999996\n",
      "Ite: 1625, Loss: 0.1055, lr: 0.4425,R: 2.96875\n",
      "Ite: 1630, Loss: 0.0971, lr: 0.4414,R: 2.9625000000000004\n",
      "Ite: 1635, Loss: 0.0879, lr: 0.4403,R: 2.9562500000000003\n",
      "Ite: 1640, Loss: 0.0801, lr: 0.4392,R: 2.95\n",
      "Ite: 1645, Loss: 0.0743, lr: 0.4381,R: 2.94375\n",
      "Ite: 1650, Loss: 0.0679, lr: 0.4370,R: 2.9375\n",
      "Ite: 1655, Loss: 0.0612, lr: 0.4359,R: 2.9312499999999995\n",
      "Ite: 1660, Loss: 0.0541, lr: 0.4348,R: 2.925\n",
      "Ite: 1665, Loss: 0.0508, lr: 0.4337,R: 2.91875\n",
      "Ite: 1670, Loss: 0.0488, lr: 0.4326,R: 2.9125\n",
      "Ite: 1675, Loss: 0.0469, lr: 0.4315,R: 2.90625\n",
      "Ite: 1680, Loss: 0.0436, lr: 0.4304,R: 2.9000000000000004\n",
      "Ite: 1685, Loss: 0.0403, lr: 0.4293,R: 2.89375\n",
      "Ite: 1690, Loss: 0.0387, lr: 0.4282,R: 2.8875\n",
      "Ite: 1695, Loss: 0.0363, lr: 0.4271,R: 2.8812499999999996\n",
      "Ite: 1700, Loss: 0.0335, lr: 0.4260,R: 2.875\n",
      "Ite: 1705, Loss: 0.0332, lr: 0.4249,R: 2.86875\n",
      "Ite: 1710, Loss: 0.0324, lr: 0.4238,R: 2.8625\n",
      "Ite: 1715, Loss: 0.0313, lr: 0.4227,R: 2.85625\n",
      "Ite: 1720, Loss: 0.0297, lr: 0.4216,R: 2.8500000000000005\n",
      "Ite: 1725, Loss: 0.0274, lr: 0.4205,R: 2.84375\n",
      "Ite: 1730, Loss: 0.0271, lr: 0.4194,R: 2.8375\n",
      "Ite: 1735, Loss: 0.0267, lr: 0.4183,R: 2.83125\n",
      "Ite: 1740, Loss: 0.0267, lr: 0.4172,R: 2.8249999999999997\n",
      "Ite: 1745, Loss: 0.0251, lr: 0.4161,R: 2.8187499999999996\n",
      "Ite: 1750, Loss: 0.0249, lr: 0.4150,R: 2.8125\n",
      "Ite: 1755, Loss: 0.0247, lr: 0.4139,R: 2.8062500000000004\n",
      "Ite: 1760, Loss: 0.0242, lr: 0.4128,R: 2.8000000000000003\n",
      "Ite: 1765, Loss: 0.0222, lr: 0.4117,R: 2.79375\n",
      "Ite: 1770, Loss: 0.0210, lr: 0.4106,R: 2.7875\n",
      "Ite: 1775, Loss: 0.0191, lr: 0.4095,R: 2.78125\n",
      "Ite: 1780, Loss: 0.0190, lr: 0.4084,R: 2.7749999999999995\n",
      "Ite: 1785, Loss: 0.0171, lr: 0.4073,R: 2.76875\n",
      "Ite: 1790, Loss: 0.0179, lr: 0.4062,R: 2.7625\n",
      "Ite: 1795, Loss: 0.0178, lr: 0.4051,R: 2.75625\n",
      "Ite: 1800, Loss: 0.0165, lr: 0.4040,R: 2.75\n",
      "Ite: 1805, Loss: 0.0154, lr: 0.4029,R: 2.7437500000000004\n",
      "Ite: 1810, Loss: 0.0139, lr: 0.4018,R: 2.7375\n",
      "Ite: 1815, Loss: 0.0149, lr: 0.4007,R: 2.73125\n",
      "Ite: 1820, Loss: 0.0147, lr: 0.3996,R: 2.7249999999999996\n",
      "Ite: 1825, Loss: 0.0135, lr: 0.3985,R: 2.71875\n",
      "Ite: 1830, Loss: 0.0135, lr: 0.3974,R: 2.7125\n",
      "Ite: 1835, Loss: 0.0140, lr: 0.3963,R: 2.70625\n",
      "Ite: 1840, Loss: 0.0128, lr: 0.3952,R: 2.7\n",
      "Ite: 1845, Loss: 0.0119, lr: 0.3941,R: 2.6937500000000005\n",
      "Ite: 1850, Loss: 0.0112, lr: 0.3930,R: 2.6875\n",
      "Ite: 1855, Loss: 0.0102, lr: 0.3919,R: 2.68125\n",
      "Ite: 1860, Loss: 0.0094, lr: 0.3908,R: 2.675\n",
      "Ite: 1865, Loss: 0.0084, lr: 0.3897,R: 2.6687499999999997\n",
      "Ite: 1870, Loss: 0.0083, lr: 0.3886,R: 2.6624999999999996\n",
      "Ite: 1875, Loss: 0.0074, lr: 0.3875,R: 2.65625\n",
      "Ite: 1880, Loss: 0.0072, lr: 0.3864,R: 2.6500000000000004\n",
      "Ite: 1885, Loss: 0.0064, lr: 0.3853,R: 2.6437500000000003\n",
      "Ite: 1890, Loss: 0.0067, lr: 0.3842,R: 2.6375\n",
      "Ite: 1895, Loss: 0.0087, lr: 0.3831,R: 2.63125\n",
      "Ite: 1900, Loss: 0.0099, lr: 0.3820,R: 2.625\n",
      "Ite: 1905, Loss: 0.0096, lr: 0.3809,R: 2.6187499999999995\n",
      "Ite: 1910, Loss: 0.0088, lr: 0.3798,R: 2.6125\n",
      "Ite: 1915, Loss: 0.0079, lr: 0.3787,R: 2.60625\n",
      "Ite: 1920, Loss: 0.0074, lr: 0.3776,R: 2.6\n",
      "Ite: 1925, Loss: 0.0080, lr: 0.3765,R: 2.59375\n",
      "Ite: 1930, Loss: 0.0095, lr: 0.3754,R: 2.5875000000000004\n",
      "Ite: 1935, Loss: 0.0086, lr: 0.3743,R: 2.58125\n",
      "Ite: 1940, Loss: 0.0081, lr: 0.3732,R: 2.575\n",
      "Ite: 1945, Loss: 0.0087, lr: 0.3721,R: 2.5687499999999996\n",
      "Ite: 1950, Loss: 0.0118, lr: 0.3710,R: 2.5625\n",
      "Ite: 1955, Loss: 0.0121, lr: 0.3699,R: 2.55625\n",
      "Ite: 1960, Loss: 0.0133, lr: 0.3688,R: 2.55\n",
      "Ite: 1965, Loss: 0.0126, lr: 0.3677,R: 2.54375\n",
      "Ite: 1970, Loss: 0.0116, lr: 0.3666,R: 2.5375000000000005\n",
      "Ite: 1975, Loss: 0.0115, lr: 0.3655,R: 2.53125\n",
      "Ite: 1980, Loss: 0.0125, lr: 0.3644,R: 2.525\n",
      "Ite: 1985, Loss: 0.0118, lr: 0.3633,R: 2.51875\n",
      "Ite: 1990, Loss: 0.0107, lr: 0.3622,R: 2.5124999999999997\n",
      "Ite: 1995, Loss: 0.0105, lr: 0.3611,R: 2.5062499999999996\n",
      "Ite: 2000, Loss: 0.0095, lr: 0.3600,R: 2.5\n",
      "Ite: 2005, Loss: 0.0095, lr: 0.3589,R: 2.4937500000000004\n",
      "Ite: 2010, Loss: 0.0108, lr: 0.3578,R: 2.4875000000000003\n",
      "Ite: 2015, Loss: 0.0117, lr: 0.3567,R: 2.4812499999999997\n",
      "Ite: 2020, Loss: 0.0118, lr: 0.3556,R: 2.475\n",
      "Ite: 2025, Loss: 0.0112, lr: 0.3545,R: 2.46875\n",
      "Ite: 2030, Loss: 0.0123, lr: 0.3534,R: 2.4625000000000004\n",
      "Ite: 2035, Loss: 0.0114, lr: 0.3523,R: 2.45625\n",
      "Ite: 2040, Loss: 0.0103, lr: 0.3512,R: 2.45\n",
      "Ite: 2045, Loss: 0.0106, lr: 0.3501,R: 2.44375\n",
      "Ite: 2050, Loss: 0.0149, lr: 0.3490,R: 2.4375\n",
      "Ite: 2055, Loss: 0.0149, lr: 0.3479,R: 2.43125\n",
      "Ite: 2060, Loss: 0.0157, lr: 0.3468,R: 2.425\n",
      "Ite: 2065, Loss: 0.0199, lr: 0.3457,R: 2.41875\n",
      "Ite: 2070, Loss: 0.0183, lr: 0.3446,R: 2.4125\n",
      "Ite: 2075, Loss: 0.0172, lr: 0.3435,R: 2.40625\n",
      "Ite: 2080, Loss: 0.0168, lr: 0.3424,R: 2.4\n",
      "Ite: 2085, Loss: 0.0175, lr: 0.3413,R: 2.39375\n",
      "Ite: 2090, Loss: 0.0161, lr: 0.3402,R: 2.3875\n",
      "Ite: 2095, Loss: 0.0150, lr: 0.3391,R: 2.3812499999999996\n",
      "Ite: 2100, Loss: 0.0141, lr: 0.3380,R: 2.375\n",
      "Ite: 2105, Loss: 0.0154, lr: 0.3369,R: 2.36875\n",
      "Ite: 2110, Loss: 0.0151, lr: 0.3358,R: 2.3625000000000003\n",
      "Ite: 2115, Loss: 0.0152, lr: 0.3347,R: 2.3562499999999997\n",
      "Ite: 2120, Loss: 0.0151, lr: 0.3336,R: 2.3499999999999996\n",
      "Ite: 2125, Loss: 0.0150, lr: 0.3325,R: 2.34375\n",
      "Ite: 2130, Loss: 0.0148, lr: 0.3314,R: 2.3375000000000004\n",
      "Ite: 2135, Loss: 0.0147, lr: 0.3303,R: 2.3312500000000003\n",
      "Ite: 2140, Loss: 0.0165, lr: 0.3292,R: 2.3249999999999997\n",
      "Ite: 2145, Loss: 0.0176, lr: 0.3281,R: 2.31875\n",
      "Ite: 2150, Loss: 0.0162, lr: 0.3270,R: 2.3125\n",
      "Ite: 2155, Loss: 0.0174, lr: 0.3259,R: 2.3062500000000004\n",
      "Ite: 2160, Loss: 0.0176, lr: 0.3248,R: 2.3\n",
      "Ite: 2165, Loss: 0.0162, lr: 0.3237,R: 2.29375\n",
      "Ite: 2170, Loss: 0.0148, lr: 0.3226,R: 2.2875\n",
      "Ite: 2175, Loss: 0.0138, lr: 0.3215,R: 2.28125\n",
      "Ite: 2180, Loss: 0.0127, lr: 0.3204,R: 2.275\n",
      "Ite: 2185, Loss: 0.0120, lr: 0.3193,R: 2.26875\n",
      "Ite: 2190, Loss: 0.0110, lr: 0.3182,R: 2.2625\n",
      "Ite: 2195, Loss: 0.0110, lr: 0.3171,R: 2.25625\n",
      "Ite: 2200, Loss: 0.0111, lr: 0.3160,R: 2.25\n",
      "Ite: 2205, Loss: 0.0103, lr: 0.3149,R: 2.24375\n",
      "Ite: 2210, Loss: 0.0103, lr: 0.3138,R: 2.2375\n",
      "Ite: 2215, Loss: 0.0107, lr: 0.3127,R: 2.23125\n",
      "Ite: 2220, Loss: 0.0112, lr: 0.3116,R: 2.2249999999999996\n",
      "Ite: 2225, Loss: 0.0103, lr: 0.3105,R: 2.21875\n",
      "Ite: 2230, Loss: 0.0095, lr: 0.3094,R: 2.2125\n",
      "Ite: 2235, Loss: 0.0091, lr: 0.3083,R: 2.2062500000000003\n",
      "Ite: 2240, Loss: 0.0086, lr: 0.3072,R: 2.1999999999999997\n",
      "Ite: 2245, Loss: 0.0080, lr: 0.3061,R: 2.1937499999999996\n",
      "Ite: 2250, Loss: 0.0090, lr: 0.3050,R: 2.1875\n",
      "Ite: 2255, Loss: 0.0083, lr: 0.3039,R: 2.1812500000000004\n",
      "Ite: 2260, Loss: 0.0077, lr: 0.3028,R: 2.1750000000000003\n",
      "Ite: 2265, Loss: 0.0076, lr: 0.3017,R: 2.1687499999999997\n",
      "Ite: 2270, Loss: 0.0090, lr: 0.3006,R: 2.1625\n",
      "Ite: 2275, Loss: 0.0093, lr: 0.2995,R: 2.15625\n",
      "Ite: 2280, Loss: 0.0089, lr: 0.2984,R: 2.1500000000000004\n",
      "Ite: 2285, Loss: 0.0079, lr: 0.2973,R: 2.14375\n",
      "Ite: 2290, Loss: 0.0073, lr: 0.2962,R: 2.1375\n",
      "Ite: 2295, Loss: 0.0070, lr: 0.2951,R: 2.13125\n",
      "Ite: 2300, Loss: 0.0072, lr: 0.2940,R: 2.125\n",
      "Ite: 2305, Loss: 0.0068, lr: 0.2929,R: 2.11875\n",
      "Ite: 2310, Loss: 0.0063, lr: 0.2918,R: 2.1125\n",
      "Ite: 2315, Loss: 0.0066, lr: 0.2907,R: 2.10625\n",
      "Ite: 2320, Loss: 0.0061, lr: 0.2896,R: 2.1\n",
      "Ite: 2325, Loss: 0.0066, lr: 0.2885,R: 2.09375\n",
      "Ite: 2330, Loss: 0.0061, lr: 0.2874,R: 2.0875\n",
      "Ite: 2335, Loss: 0.0058, lr: 0.2863,R: 2.08125\n",
      "Ite: 2340, Loss: 0.0054, lr: 0.2852,R: 2.075\n",
      "Ite: 2345, Loss: 0.0057, lr: 0.2841,R: 2.0687499999999996\n",
      "Ite: 2350, Loss: 0.0081, lr: 0.2830,R: 2.0625\n",
      "Ite: 2355, Loss: 0.0080, lr: 0.2819,R: 2.05625\n",
      "Ite: 2360, Loss: 0.0074, lr: 0.2808,R: 2.0500000000000003\n",
      "Ite: 2365, Loss: 0.0079, lr: 0.2797,R: 2.0437499999999997\n",
      "Ite: 2370, Loss: 0.0073, lr: 0.2786,R: 2.0374999999999996\n",
      "Ite: 2375, Loss: 0.0067, lr: 0.2775,R: 2.03125\n",
      "Ite: 2380, Loss: 0.0067, lr: 0.2764,R: 2.0250000000000004\n",
      "Ite: 2385, Loss: 0.0065, lr: 0.2753,R: 2.0187500000000003\n",
      "Ite: 2390, Loss: 0.0060, lr: 0.2742,R: 2.0124999999999997\n",
      "Ite: 2395, Loss: 0.0056, lr: 0.2731,R: 2.00625\n",
      "Ite: 2400, Loss: 0.0054, lr: 0.2720,R: 2.0\n",
      "Ite: 2405, Loss: 0.0714, lr: 0.2709,R: 1.9937500000000004\n",
      "Ite: 2410, Loss: 0.0684, lr: 0.2698,R: 1.9874999999999998\n",
      "Ite: 2415, Loss: 0.0653, lr: 0.2687,R: 1.98125\n",
      "Ite: 2420, Loss: 0.0620, lr: 0.2676,R: 1.975\n",
      "Ite: 2425, Loss: 0.0590, lr: 0.2665,R: 1.9687500000000002\n",
      "Ite: 2430, Loss: 0.0561, lr: 0.2654,R: 1.9625\n",
      "Ite: 2435, Loss: 0.0523, lr: 0.2643,R: 1.9562499999999998\n",
      "Ite: 2440, Loss: 0.0502, lr: 0.2632,R: 1.9500000000000002\n",
      "Ite: 2445, Loss: 0.0476, lr: 0.2621,R: 1.94375\n",
      "Ite: 2450, Loss: 0.0455, lr: 0.2610,R: 1.9374999999999998\n",
      "Ite: 2455, Loss: 0.0437, lr: 0.2599,R: 1.93125\n",
      "Ite: 2460, Loss: 0.0419, lr: 0.2588,R: 1.925\n",
      "Ite: 2465, Loss: 0.0404, lr: 0.2577,R: 1.9187500000000002\n",
      "Ite: 2470, Loss: 0.0388, lr: 0.2566,R: 1.9124999999999996\n",
      "Ite: 2475, Loss: 0.0374, lr: 0.2555,R: 1.90625\n",
      "Ite: 2480, Loss: 0.0360, lr: 0.2544,R: 1.9\n",
      "Ite: 2485, Loss: 0.0350, lr: 0.2533,R: 1.8937500000000003\n",
      "Ite: 2490, Loss: 0.0333, lr: 0.2522,R: 1.8874999999999997\n",
      "Ite: 2495, Loss: 0.0321, lr: 0.2511,R: 1.8812499999999999\n",
      "Ite: 2500, Loss: 0.0308, lr: 0.2500,R: 1.875\n",
      "Ite: 2505, Loss: 0.0297, lr: 0.2489,R: 1.8687500000000001\n",
      "Ite: 2510, Loss: 0.0287, lr: 0.2478,R: 1.8625000000000003\n",
      "Ite: 2515, Loss: 0.0275, lr: 0.2467,R: 1.8562499999999997\n",
      "Ite: 2520, Loss: 0.0269, lr: 0.2456,R: 1.85\n",
      "Ite: 2525, Loss: 0.0257, lr: 0.2445,R: 1.84375\n",
      "Ite: 2530, Loss: 0.0250, lr: 0.2434,R: 1.8375000000000004\n",
      "Ite: 2535, Loss: 0.0242, lr: 0.2423,R: 1.8312499999999998\n",
      "Ite: 2540, Loss: 0.0234, lr: 0.2412,R: 1.825\n",
      "Ite: 2545, Loss: 0.0230, lr: 0.2401,R: 1.81875\n",
      "Ite: 2550, Loss: 0.0224, lr: 0.2390,R: 1.8125000000000002\n",
      "Ite: 2555, Loss: 0.0218, lr: 0.2379,R: 1.80625\n",
      "Ite: 2560, Loss: 0.0213, lr: 0.2368,R: 1.7999999999999998\n",
      "Ite: 2565, Loss: 0.0207, lr: 0.2357,R: 1.7937500000000002\n",
      "Ite: 2570, Loss: 0.0202, lr: 0.2346,R: 1.7875\n",
      "Ite: 2575, Loss: 0.0199, lr: 0.2335,R: 1.7812499999999998\n",
      "Ite: 2580, Loss: 0.0194, lr: 0.2324,R: 1.775\n",
      "Ite: 2585, Loss: 0.0184, lr: 0.2313,R: 1.76875\n",
      "Ite: 2590, Loss: 0.0178, lr: 0.2302,R: 1.7625000000000002\n",
      "Ite: 2595, Loss: 0.0172, lr: 0.2291,R: 1.7562499999999996\n",
      "Ite: 2600, Loss: 0.0168, lr: 0.2280,R: 1.75\n",
      "Ite: 2605, Loss: 0.0163, lr: 0.2269,R: 1.74375\n",
      "Ite: 2610, Loss: 0.0163, lr: 0.2258,R: 1.7375000000000003\n",
      "Ite: 2615, Loss: 0.0158, lr: 0.2247,R: 1.7312499999999997\n",
      "Ite: 2620, Loss: 0.0154, lr: 0.2236,R: 1.7249999999999999\n",
      "Ite: 2625, Loss: 0.0155, lr: 0.2225,R: 1.71875\n",
      "Ite: 2630, Loss: 0.0152, lr: 0.2214,R: 1.7125000000000001\n",
      "Ite: 2635, Loss: 0.0147, lr: 0.2203,R: 1.7062500000000003\n",
      "Ite: 2640, Loss: 0.0142, lr: 0.2192,R: 1.6999999999999997\n",
      "Ite: 2645, Loss: 0.0137, lr: 0.2181,R: 1.69375\n",
      "Ite: 2650, Loss: 0.0134, lr: 0.2170,R: 1.6875\n",
      "Ite: 2655, Loss: 0.0130, lr: 0.2159,R: 1.6812500000000004\n",
      "Ite: 2660, Loss: 0.0127, lr: 0.2148,R: 1.6749999999999998\n",
      "Ite: 2665, Loss: 0.0122, lr: 0.2137,R: 1.66875\n",
      "Ite: 2670, Loss: 0.0119, lr: 0.2126,R: 1.6625\n",
      "Ite: 2675, Loss: 0.0118, lr: 0.2115,R: 1.6562500000000002\n",
      "Ite: 2680, Loss: 0.0117, lr: 0.2104,R: 1.65\n",
      "Ite: 2685, Loss: 0.0116, lr: 0.2093,R: 1.6437499999999998\n",
      "Ite: 2690, Loss: 0.0115, lr: 0.2082,R: 1.6375000000000002\n",
      "Ite: 2695, Loss: 0.0114, lr: 0.2071,R: 1.63125\n",
      "Ite: 2700, Loss: 0.0112, lr: 0.2060,R: 1.6249999999999998\n",
      "Ite: 2705, Loss: 0.0116, lr: 0.2049,R: 1.61875\n",
      "Ite: 2710, Loss: 0.0115, lr: 0.2038,R: 1.6125\n",
      "Ite: 2715, Loss: 0.0113, lr: 0.2027,R: 1.6062500000000002\n",
      "Ite: 2720, Loss: 0.0112, lr: 0.2016,R: 1.5999999999999996\n",
      "Ite: 2725, Loss: 0.0114, lr: 0.2005,R: 1.59375\n",
      "Ite: 2730, Loss: 0.0113, lr: 0.1994,R: 1.5875\n",
      "Ite: 2735, Loss: 0.0110, lr: 0.1983,R: 1.5812500000000003\n",
      "Ite: 2740, Loss: 0.0109, lr: 0.1972,R: 1.5749999999999997\n",
      "Ite: 2745, Loss: 0.0108, lr: 0.1961,R: 1.5687499999999999\n",
      "Ite: 2750, Loss: 0.0104, lr: 0.1950,R: 1.5625\n",
      "Ite: 2755, Loss: 0.0103, lr: 0.1939,R: 1.5562500000000001\n",
      "Ite: 2760, Loss: 0.0105, lr: 0.1928,R: 1.5500000000000003\n",
      "Ite: 2765, Loss: 0.0105, lr: 0.1917,R: 1.5437499999999997\n",
      "Ite: 2770, Loss: 0.0101, lr: 0.1906,R: 1.5375\n",
      "Ite: 2775, Loss: 0.0099, lr: 0.1895,R: 1.53125\n",
      "Ite: 2780, Loss: 0.0096, lr: 0.1884,R: 1.5250000000000004\n",
      "Ite: 2785, Loss: 0.0094, lr: 0.1873,R: 1.5187499999999998\n",
      "Ite: 2790, Loss: 0.0094, lr: 0.1862,R: 1.5125\n",
      "Ite: 2795, Loss: 0.0095, lr: 0.1851,R: 1.50625\n",
      "Ite: 2800, Loss: 0.0097, lr: 0.1840,R: 1.5000000000000002\n",
      "Ite: 2805, Loss: 0.0096, lr: 0.1829,R: 1.49375\n",
      "Ite: 2810, Loss: 0.0093, lr: 0.1818,R: 1.4874999999999998\n",
      "Ite: 2815, Loss: 0.0094, lr: 0.1807,R: 1.4812500000000002\n",
      "Ite: 2820, Loss: 0.0091, lr: 0.1796,R: 1.475\n",
      "Ite: 2825, Loss: 0.0090, lr: 0.1785,R: 1.4687499999999998\n",
      "Ite: 2830, Loss: 0.0088, lr: 0.1774,R: 1.4625\n",
      "Ite: 2835, Loss: 0.0085, lr: 0.1763,R: 1.45625\n",
      "Ite: 2840, Loss: 0.0083, lr: 0.1752,R: 1.4500000000000002\n",
      "Ite: 2845, Loss: 0.0083, lr: 0.1741,R: 1.4437499999999996\n",
      "Ite: 2850, Loss: 0.0081, lr: 0.1730,R: 1.4375\n",
      "Ite: 2855, Loss: 0.0080, lr: 0.1719,R: 1.43125\n",
      "Ite: 2860, Loss: 0.0077, lr: 0.1708,R: 1.4250000000000003\n",
      "Ite: 2865, Loss: 0.0075, lr: 0.1697,R: 1.4187499999999997\n",
      "Ite: 2870, Loss: 0.0075, lr: 0.1686,R: 1.4124999999999999\n",
      "Ite: 2875, Loss: 0.0073, lr: 0.1675,R: 1.40625\n",
      "Ite: 2880, Loss: 0.0071, lr: 0.1664,R: 1.4000000000000001\n",
      "Ite: 2885, Loss: 0.0073, lr: 0.1653,R: 1.3937500000000003\n",
      "Ite: 2890, Loss: 0.0073, lr: 0.1642,R: 1.3874999999999997\n",
      "Ite: 2895, Loss: 0.0074, lr: 0.1631,R: 1.38125\n",
      "Ite: 2900, Loss: 0.0072, lr: 0.1620,R: 1.375\n",
      "Ite: 2905, Loss: 0.0077, lr: 0.1609,R: 1.3687500000000004\n",
      "Ite: 2910, Loss: 0.0075, lr: 0.1598,R: 1.3624999999999998\n",
      "Ite: 2915, Loss: 0.0076, lr: 0.1587,R: 1.35625\n",
      "Ite: 2920, Loss: 0.0075, lr: 0.1576,R: 1.35\n",
      "Ite: 2925, Loss: 0.0076, lr: 0.1565,R: 1.3437500000000002\n",
      "Ite: 2930, Loss: 0.0074, lr: 0.1554,R: 1.3375\n",
      "Ite: 2935, Loss: 0.0072, lr: 0.1543,R: 1.3312499999999998\n",
      "Ite: 2940, Loss: 0.0070, lr: 0.1532,R: 1.3250000000000002\n",
      "Ite: 2945, Loss: 0.0070, lr: 0.1521,R: 1.31875\n",
      "Ite: 2950, Loss: 0.0069, lr: 0.1510,R: 1.3124999999999998\n",
      "Ite: 2955, Loss: 0.0067, lr: 0.1499,R: 1.30625\n",
      "Ite: 2960, Loss: 0.0066, lr: 0.1488,R: 1.3\n",
      "Ite: 2965, Loss: 0.0064, lr: 0.1477,R: 1.2937500000000002\n",
      "Ite: 2970, Loss: 0.0063, lr: 0.1466,R: 1.2874999999999996\n",
      "Ite: 2975, Loss: 0.0061, lr: 0.1455,R: 1.28125\n",
      "Ite: 2980, Loss: 0.0060, lr: 0.1444,R: 1.275\n",
      "Ite: 2985, Loss: 0.0058, lr: 0.1433,R: 1.2687500000000003\n",
      "Ite: 2990, Loss: 0.0057, lr: 0.1422,R: 1.2624999999999997\n",
      "Ite: 2995, Loss: 0.0055, lr: 0.1411,R: 1.2562499999999999\n",
      "Ite: 3000, Loss: 0.0055, lr: 0.1400,R: 1.25\n",
      "Ite: 3005, Loss: 0.0053, lr: 0.1389,R: 1.2437500000000001\n",
      "Ite: 3010, Loss: 0.0052, lr: 0.1378,R: 1.2375000000000003\n",
      "Ite: 3015, Loss: 0.0053, lr: 0.1367,R: 1.2312499999999997\n",
      "Ite: 3020, Loss: 0.0052, lr: 0.1356,R: 1.225\n",
      "Ite: 3025, Loss: 0.0051, lr: 0.1345,R: 1.21875\n",
      "Ite: 3030, Loss: 0.0050, lr: 0.1334,R: 1.2125000000000004\n",
      "Ite: 3035, Loss: 0.0049, lr: 0.1323,R: 1.2062499999999998\n",
      "Ite: 3040, Loss: 0.0047, lr: 0.1312,R: 1.2\n",
      "Ite: 3045, Loss: 0.0046, lr: 0.1301,R: 1.19375\n",
      "Ite: 3050, Loss: 0.0045, lr: 0.1290,R: 1.1875000000000002\n",
      "Ite: 3055, Loss: 0.0044, lr: 0.1279,R: 1.18125\n",
      "Ite: 3060, Loss: 0.0043, lr: 0.1268,R: 1.1749999999999998\n",
      "Ite: 3065, Loss: 0.0045, lr: 0.1257,R: 1.1687500000000002\n",
      "Ite: 3070, Loss: 0.0043, lr: 0.1246,R: 1.1625\n",
      "Ite: 3075, Loss: 0.0042, lr: 0.1235,R: 1.1562499999999998\n",
      "Ite: 3080, Loss: 0.0041, lr: 0.1224,R: 1.15\n",
      "Ite: 3085, Loss: 0.0040, lr: 0.1213,R: 1.14375\n",
      "Ite: 3090, Loss: 0.0039, lr: 0.1202,R: 1.1375000000000002\n",
      "Ite: 3095, Loss: 0.0038, lr: 0.1191,R: 1.1312499999999996\n",
      "Ite: 3100, Loss: 0.0038, lr: 0.1180,R: 1.125\n",
      "Ite: 3105, Loss: 0.0037, lr: 0.1169,R: 1.11875\n",
      "Ite: 3110, Loss: 0.0036, lr: 0.1158,R: 1.1125000000000003\n",
      "Ite: 3115, Loss: 0.0035, lr: 0.1147,R: 1.1062499999999997\n",
      "Ite: 3120, Loss: 0.0035, lr: 0.1136,R: 1.0999999999999999\n",
      "Ite: 3125, Loss: 0.0034, lr: 0.1125,R: 1.09375\n",
      "Ite: 3130, Loss: 0.0033, lr: 0.1114,R: 1.0875000000000001\n",
      "Ite: 3135, Loss: 0.0032, lr: 0.1103,R: 1.0812500000000003\n",
      "Ite: 3140, Loss: 0.0031, lr: 0.1092,R: 1.0749999999999997\n",
      "Ite: 3145, Loss: 0.0031, lr: 0.1081,R: 1.06875\n",
      "Ite: 3150, Loss: 0.0030, lr: 0.1070,R: 1.0625\n",
      "Ite: 3155, Loss: 0.0029, lr: 0.1059,R: 1.0562500000000004\n",
      "Ite: 3160, Loss: 0.0028, lr: 0.1048,R: 1.0499999999999998\n",
      "Ite: 3165, Loss: 0.0028, lr: 0.1037,R: 1.04375\n",
      "Ite: 3170, Loss: 0.0027, lr: 0.1026,R: 1.0375\n",
      "Ite: 3175, Loss: 0.0026, lr: 0.1015,R: 1.0312500000000002\n",
      "Ite: 3180, Loss: 0.0026, lr: 0.1004,R: 1.025\n",
      "Ite: 3185, Loss: 0.0025, lr: 0.0993,R: 1.0187499999999998\n",
      "Ite: 3190, Loss: 0.0025, lr: 0.0982,R: 1.0125000000000002\n",
      "Ite: 3195, Loss: 0.0024, lr: 0.0971,R: 1.00625\n",
      "Ite: 3200, Loss: 0.0024, lr: 0.0960,R: 0.9999999999999998\n",
      "Ite: 3205, Loss: 0.0125, lr: 0.0949,R: 0.9937499999999999\n",
      "Ite: 3210, Loss: 0.0122, lr: 0.0938,R: 0.9875\n",
      "Ite: 3215, Loss: 0.0120, lr: 0.0927,R: 0.9812500000000002\n",
      "Ite: 3220, Loss: 0.0118, lr: 0.0916,R: 0.9749999999999998\n",
      "Ite: 3225, Loss: 0.0117, lr: 0.0905,R: 0.9687499999999999\n",
      "Ite: 3230, Loss: 0.0115, lr: 0.0894,R: 0.9625\n",
      "Ite: 3235, Loss: 0.0113, lr: 0.0883,R: 0.9562500000000002\n",
      "Ite: 3240, Loss: 0.0111, lr: 0.0872,R: 0.9499999999999997\n",
      "Ite: 3245, Loss: 0.0109, lr: 0.0861,R: 0.9437499999999999\n",
      "Ite: 3250, Loss: 0.0107, lr: 0.0850,R: 0.9375\n",
      "Ite: 3255, Loss: 0.0105, lr: 0.0839,R: 0.9312500000000001\n",
      "Ite: 3260, Loss: 0.0103, lr: 0.0828,R: 0.9250000000000003\n",
      "Ite: 3265, Loss: 0.0101, lr: 0.0817,R: 0.9187499999999998\n",
      "Ite: 3270, Loss: 0.0099, lr: 0.0806,R: 0.9125\n",
      "Ite: 3275, Loss: 0.0097, lr: 0.0795,R: 0.9062500000000001\n",
      "Ite: 3280, Loss: 0.0095, lr: 0.0784,R: 0.9000000000000002\n",
      "Ite: 3285, Loss: 0.0094, lr: 0.0773,R: 0.8937499999999998\n",
      "Ite: 3290, Loss: 0.0093, lr: 0.0762,R: 0.8875\n",
      "Ite: 3295, Loss: 0.0091, lr: 0.0751,R: 0.8812500000000001\n",
      "Ite: 3300, Loss: 0.0089, lr: 0.0740,R: 0.8750000000000002\n",
      "Ite: 3305, Loss: 0.0087, lr: 0.0729,R: 0.8687499999999998\n",
      "Ite: 3310, Loss: 0.0086, lr: 0.0718,R: 0.8624999999999999\n",
      "Ite: 3315, Loss: 0.0084, lr: 0.0707,R: 0.8562500000000001\n",
      "Ite: 3320, Loss: 0.0082, lr: 0.0696,R: 0.8500000000000002\n",
      "Ite: 3325, Loss: 0.0080, lr: 0.0685,R: 0.8437499999999998\n",
      "Ite: 3330, Loss: 0.0079, lr: 0.0674,R: 0.8374999999999999\n",
      "Ite: 3335, Loss: 0.0077, lr: 0.0663,R: 0.83125\n",
      "Ite: 3340, Loss: 0.0075, lr: 0.0652,R: 0.8250000000000002\n",
      "Ite: 3345, Loss: 0.0074, lr: 0.0641,R: 0.8187499999999998\n",
      "Ite: 3350, Loss: 0.0072, lr: 0.0630,R: 0.8124999999999999\n",
      "Ite: 3355, Loss: 0.0071, lr: 0.0619,R: 0.80625\n",
      "Ite: 3360, Loss: 0.0070, lr: 0.0608,R: 0.8000000000000002\n",
      "Ite: 3365, Loss: 0.0068, lr: 0.0597,R: 0.7937499999999997\n",
      "Ite: 3370, Loss: 0.0067, lr: 0.0586,R: 0.7874999999999999\n",
      "Ite: 3375, Loss: 0.0065, lr: 0.0575,R: 0.78125\n",
      "Ite: 3380, Loss: 0.0064, lr: 0.0564,R: 0.7750000000000001\n",
      "Ite: 3385, Loss: 0.0062, lr: 0.0553,R: 0.7687500000000003\n",
      "Ite: 3390, Loss: 0.0061, lr: 0.0542,R: 0.7624999999999998\n",
      "Ite: 3395, Loss: 0.0060, lr: 0.0531,R: 0.75625\n",
      "Ite: 3400, Loss: 0.0058, lr: 0.0520,R: 0.7500000000000001\n",
      "Ite: 3405, Loss: 0.0057, lr: 0.0509,R: 0.7437500000000002\n",
      "Ite: 3410, Loss: 0.0055, lr: 0.0498,R: 0.7374999999999998\n",
      "Ite: 3415, Loss: 0.0054, lr: 0.0487,R: 0.73125\n",
      "Ite: 3420, Loss: 0.0053, lr: 0.0476,R: 0.7250000000000001\n",
      "Ite: 3425, Loss: 0.0051, lr: 0.0465,R: 0.7187500000000002\n",
      "Ite: 3430, Loss: 0.0050, lr: 0.0454,R: 0.7124999999999998\n",
      "Ite: 3435, Loss: 0.0049, lr: 0.0443,R: 0.7062499999999999\n",
      "Ite: 3440, Loss: 0.0047, lr: 0.0432,R: 0.7000000000000001\n",
      "Ite: 3445, Loss: 0.0046, lr: 0.0421,R: 0.6937500000000002\n",
      "Ite: 3450, Loss: 0.0045, lr: 0.0410,R: 0.6874999999999998\n",
      "Ite: 3455, Loss: 0.0043, lr: 0.0399,R: 0.6812499999999999\n",
      "Ite: 3460, Loss: 0.0042, lr: 0.0388,R: 0.675\n",
      "Ite: 3465, Loss: 0.0041, lr: 0.0377,R: 0.6687500000000002\n",
      "Ite: 3470, Loss: 0.0039, lr: 0.0366,R: 0.6624999999999998\n",
      "Ite: 3475, Loss: 0.0038, lr: 0.0355,R: 0.6562499999999999\n",
      "Ite: 3480, Loss: 0.0037, lr: 0.0344,R: 0.65\n",
      "Ite: 3485, Loss: 0.0036, lr: 0.0333,R: 0.6437500000000002\n",
      "Ite: 3490, Loss: 0.0034, lr: 0.0322,R: 0.6374999999999997\n",
      "Ite: 3495, Loss: 0.0033, lr: 0.0311,R: 0.6312499999999999\n",
      "Ite: 3500, Loss: 0.0032, lr: 0.0300,R: 0.625\n",
      "Ite: 3505, Loss: 0.0031, lr: 0.0289,R: 0.6187500000000001\n",
      "Ite: 3510, Loss: 0.0030, lr: 0.0278,R: 0.6125000000000003\n",
      "Ite: 3515, Loss: 0.0028, lr: 0.0267,R: 0.6062499999999998\n",
      "Ite: 3520, Loss: 0.0027, lr: 0.0256,R: 0.6\n",
      "Ite: 3525, Loss: 0.0026, lr: 0.0245,R: 0.5937500000000001\n",
      "Ite: 3530, Loss: 0.0025, lr: 0.0234,R: 0.5875000000000002\n",
      "Ite: 3535, Loss: 0.0024, lr: 0.0223,R: 0.5812499999999998\n",
      "Ite: 3540, Loss: 0.0022, lr: 0.0212,R: 0.575\n",
      "Ite: 3545, Loss: 0.0021, lr: 0.0201,R: 0.5687500000000001\n",
      "Ite: 3550, Loss: 0.0020, lr: 0.0190,R: 0.5625000000000002\n",
      "Ite: 3555, Loss: 0.0019, lr: 0.0179,R: 0.5562499999999998\n",
      "Ite: 3560, Loss: 0.0018, lr: 0.0168,R: 0.5499999999999999\n",
      "Ite: 3565, Loss: 0.0017, lr: 0.0157,R: 0.5437500000000001\n",
      "Ite: 3570, Loss: 0.0016, lr: 0.0146,R: 0.5375000000000002\n",
      "Ite: 3575, Loss: 0.0014, lr: 0.0135,R: 0.5312499999999998\n",
      "Ite: 3580, Loss: 0.0013, lr: 0.0124,R: 0.5249999999999999\n",
      "Ite: 3585, Loss: 0.0012, lr: 0.0113,R: 0.51875\n",
      "Ite: 3590, Loss: 0.0011, lr: 0.0102,R: 0.5125000000000002\n",
      "Ite: 3595, Loss: 0.0010, lr: 0.0091,R: 0.5062499999999998\n",
      "Ite: 3600, Loss: 0.0009, lr: 0.0080,R: 0.4999999999999999\n",
      "Ite: 3605, Loss: 0.0007, lr: 0.0069,R: 0.49375\n",
      "Ite: 3610, Loss: 0.0006, lr: 0.0058,R: 0.48750000000000016\n",
      "Ite: 3615, Loss: 0.0005, lr: 0.0047,R: 0.48124999999999973\n",
      "Ite: 3620, Loss: 0.0004, lr: 0.0036,R: 0.47499999999999987\n",
      "Ite: 3625, Loss: 0.0003, lr: 0.0025,R: 0.46875\n",
      "Ite: 3630, Loss: 0.0002, lr: 0.0014,R: 0.46250000000000013\n",
      "Ite: 3635, Loss: 0.0001, lr: 0.0003,R: 0.45625000000000027\n",
      "Ite: 3640, Loss: 0.0001, lr: -0.0008,R: 0.44999999999999984\n",
      "Ite: 3645, Loss: 0.0002, lr: -0.0019,R: 0.44375\n",
      "Ite: 3650, Loss: 0.0003, lr: -0.0030,R: 0.4375000000000001\n",
      "Ite: 3655, Loss: 0.0004, lr: -0.0041,R: 0.43125000000000024\n",
      "Ite: 3660, Loss: 0.0005, lr: -0.0052,R: 0.4249999999999998\n",
      "Ite: 3665, Loss: 0.0006, lr: -0.0063,R: 0.41874999999999996\n",
      "Ite: 3670, Loss: 0.0007, lr: -0.0074,R: 0.4125000000000001\n",
      "Ite: 3675, Loss: 0.0009, lr: -0.0085,R: 0.4062500000000002\n",
      "Ite: 3680, Loss: 0.0010, lr: -0.0096,R: 0.3999999999999998\n",
      "Ite: 3685, Loss: 0.0011, lr: -0.0107,R: 0.39374999999999993\n",
      "Ite: 3690, Loss: 0.0012, lr: -0.0118,R: 0.38750000000000007\n",
      "Ite: 3695, Loss: 0.0013, lr: -0.0129,R: 0.3812500000000002\n",
      "Ite: 3700, Loss: 0.0014, lr: -0.0140,R: 0.3749999999999998\n",
      "Ite: 3705, Loss: 0.0016, lr: -0.0151,R: 0.3687499999999999\n",
      "Ite: 3710, Loss: 0.0017, lr: -0.0162,R: 0.36250000000000004\n",
      "Ite: 3715, Loss: 0.0018, lr: -0.0173,R: 0.3562500000000002\n",
      "Ite: 3720, Loss: 0.0019, lr: -0.0184,R: 0.34999999999999976\n",
      "Ite: 3725, Loss: 0.0020, lr: -0.0195,R: 0.3437499999999999\n",
      "Ite: 3730, Loss: 0.0021, lr: -0.0206,R: 0.3375\n",
      "Ite: 3735, Loss: 0.0023, lr: -0.0217,R: 0.33125000000000016\n",
      "Ite: 3740, Loss: 0.0024, lr: -0.0228,R: 0.32499999999999973\n",
      "Ite: 3745, Loss: 0.0025, lr: -0.0239,R: 0.31874999999999987\n",
      "Ite: 3750, Loss: 0.0026, lr: -0.0250,R: 0.3125\n",
      "Ite: 3755, Loss: 0.0027, lr: -0.0261,R: 0.30625000000000013\n",
      "Ite: 3760, Loss: 0.0028, lr: -0.0272,R: 0.30000000000000027\n",
      "Ite: 3765, Loss: 0.0030, lr: -0.0283,R: 0.29374999999999984\n",
      "Ite: 3770, Loss: 0.0031, lr: -0.0294,R: 0.2875\n",
      "Ite: 3775, Loss: 0.0032, lr: -0.0305,R: 0.2812500000000001\n",
      "Ite: 3780, Loss: 0.0033, lr: -0.0316,R: 0.27500000000000024\n",
      "Ite: 3785, Loss: 0.0035, lr: -0.0327,R: 0.2687499999999998\n",
      "Ite: 3790, Loss: 0.0036, lr: -0.0338,R: 0.26249999999999996\n",
      "Ite: 3795, Loss: 0.0037, lr: -0.0349,R: 0.2562500000000001\n",
      "Ite: 3800, Loss: 0.0038, lr: -0.0360,R: 0.2500000000000002\n",
      "Ite: 3805, Loss: 0.0039, lr: -0.0371,R: 0.2437499999999998\n",
      "Ite: 3810, Loss: 0.0041, lr: -0.0382,R: 0.23749999999999993\n",
      "Ite: 3815, Loss: 0.0042, lr: -0.0393,R: 0.23125000000000007\n",
      "Ite: 3820, Loss: 0.0043, lr: -0.0404,R: 0.2250000000000002\n",
      "Ite: 3825, Loss: 0.0045, lr: -0.0415,R: 0.21874999999999978\n",
      "Ite: 3830, Loss: 0.0046, lr: -0.0426,R: 0.2124999999999999\n",
      "Ite: 3835, Loss: 0.0047, lr: -0.0437,R: 0.20625000000000004\n",
      "Ite: 3840, Loss: 0.0049, lr: -0.0448,R: 0.20000000000000018\n",
      "Ite: 3845, Loss: 0.0050, lr: -0.0459,R: 0.19374999999999976\n",
      "Ite: 3850, Loss: 0.0051, lr: -0.0470,R: 0.1874999999999999\n",
      "Ite: 3855, Loss: 0.0053, lr: -0.0481,R: 0.18125000000000002\n",
      "Ite: 3860, Loss: 0.0054, lr: -0.0492,R: 0.17500000000000016\n",
      "Ite: 3865, Loss: 0.0055, lr: -0.0503,R: 0.16874999999999973\n",
      "Ite: 3870, Loss: 0.0057, lr: -0.0514,R: 0.16249999999999987\n",
      "Ite: 3875, Loss: 0.0058, lr: -0.0525,R: 0.15625\n",
      "Ite: 3880, Loss: 0.0060, lr: -0.0536,R: 0.15000000000000013\n",
      "Ite: 3885, Loss: 0.0061, lr: -0.0547,R: 0.14375000000000027\n",
      "Ite: 3890, Loss: 0.0062, lr: -0.0558,R: 0.13749999999999984\n",
      "Ite: 3895, Loss: 0.0064, lr: -0.0569,R: 0.13124999999999998\n",
      "Ite: 3900, Loss: 0.0065, lr: -0.0580,R: 0.1250000000000001\n",
      "Ite: 3905, Loss: 0.0067, lr: -0.0591,R: 0.11875000000000024\n",
      "Ite: 3910, Loss: 0.0068, lr: -0.0602,R: 0.11249999999999982\n",
      "Ite: 3915, Loss: 0.0070, lr: -0.0613,R: 0.10624999999999996\n",
      "Ite: 3920, Loss: 0.0071, lr: -0.0624,R: 0.10000000000000009\n",
      "Ite: 3925, Loss: 0.0072, lr: -0.0635,R: 0.09375000000000022\n",
      "Ite: 3930, Loss: 0.0074, lr: -0.0646,R: 0.0874999999999998\n",
      "Ite: 3935, Loss: 0.0076, lr: -0.0657,R: 0.08124999999999993\n",
      "Ite: 3940, Loss: 0.0077, lr: -0.0668,R: 0.07500000000000007\n",
      "Ite: 3945, Loss: 0.0079, lr: -0.0679,R: 0.0687500000000002\n",
      "Ite: 3950, Loss: 0.0081, lr: -0.0690,R: 0.06249999999999978\n",
      "Ite: 3955, Loss: 0.0082, lr: -0.0701,R: 0.05624999999999991\n",
      "Ite: 3960, Loss: 0.0084, lr: -0.0712,R: 0.050000000000000044\n",
      "Ite: 3965, Loss: 0.0086, lr: -0.0723,R: 0.04375000000000018\n",
      "Ite: 3970, Loss: 0.0087, lr: -0.0734,R: 0.037499999999999756\n",
      "Ite: 3975, Loss: 0.0089, lr: -0.0745,R: 0.03124999999999989\n",
      "Ite: 3980, Loss: 0.0091, lr: -0.0756,R: 0.025000000000000022\n",
      "Ite: 3985, Loss: 0.0093, lr: -0.0767,R: 0.018750000000000155\n",
      "Ite: 3990, Loss: 0.0094, lr: -0.0778,R: 0.012499999999999734\n",
      "Ite: 3995, Loss: 0.0096, lr: -0.0789,R: 0.006249999999999867\n",
      "Ite: 3999, Loss: 0.0097, lr: -0.0798,R: 0.0012499999999998623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "som = CustomSOM((9,9),lr=0.8,radius=5,features_count=561)\n",
    "som.train(X_valid,4000,lr_decay=1.1)\n",
    "\n",
    "plt.subplot(5,1,1)\n",
    "som.visualize(X_valid,Y_valid)\n",
    "plt.subplot(5,1,2)\n",
    "som.get_u_matrix(True)\n",
    "plt.subplot(5,1,3)\n",
    "data = {\"Iteration\":list(range(len(som.loss))),\"Loss\":som.loss}\n",
    "sns.lineplot(data=data,x=\"Iteration\",y=\"Loss\")\n",
    "plt.title(\"Loss of Network\")\n",
    "plt.subplot(5,1,4)\n",
    "data = {\"Iteration\":list(range(len(som.dead_neurons))),\"Dead Neuron\":som.dead_neurons}\n",
    "sns.lineplot(data=data,x=\"Iteration\",y=\"Dead Neuron\")\n",
    "plt.title(\"Dead Neurons of Network\")\n",
    "\n",
    "plt.subplot(5,1,5)\n",
    "data = {\"Iteration\":list(range(len(som.distance_mean))),\"Mean Distance\":som.distance_mean}\n",
    "sns.lineplot(data=data,x=\"Iteration\",y=\"Mean Distance\")\n",
    "plt.title(\"Mean Distance to Winners\")\n",
    "plt.savefig(\"decay {0} - radius {1} - grid size ({2}-{2})-3.png\".format(1,5,9))\n",
    "plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid = som.dataset_transform(X_valid)\n",
    "new_train = som.dataset_transform(X_train)\n",
    "new_test = som.dataset_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save transformed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_test.npy', 'wb') as f:\n",
    "    np.save(f, new_test)\n",
    "    \n",
    "with open('X_valid.npy', 'wb') as f:\n",
    "    np.save(f, new_valid)\n",
    "\n",
    "with open('X_train.npy', 'wb') as f:\n",
    "    np.save(f, new_train)\n",
    "    \n",
    "with open('Y_test.npy', 'wb') as f:\n",
    "    np.save(f, Y_test)\n",
    "    \n",
    "with open('Y_valid.npy', 'wb') as f:\n",
    "    np.save(f, Y_valid)\n",
    "\n",
    "with open('Y_train.npy', 'wb') as f:\n",
    "    np.save(f, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f58f5e3d824a28f35e64a3b79d7f63edde6993a3dcc3aa79d0be3205de7b8a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
